<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sauron Lee‘blog</title>
  
  <subtitle>www.xiaoranli.com</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://github.com/SauronLee/"/>
  <updated>2021-03-26T20:54:18.950Z</updated>
  <id>https://github.com/SauronLee/</id>
  
  <author>
    <name>Xiaoran Li</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Research Notes In March 2021</title>
    <link href="https://github.com/SauronLee/2021/03/24/siroita/"/>
    <id>https://github.com/SauronLee/2021/03/24/siroita/</id>
    <published>2021-03-24T01:19:27.000Z</published>
    <updated>2021-03-26T20:54:18.950Z</updated>
    
    <content type="html"><![CDATA[<div class="row">    <embed src="/pdf/Research2103_notes.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
    
    <summary type="html">
    
      
      
        

	&lt;div class=&quot;row&quot;&gt;
    &lt;embed src=&quot;/pdf/Research2103_notes.pdf&quot; width=&quot;100%&quot; height=&quot;550&quot; type=&quot;application/pdf&quot;&gt;
	&lt;/div&gt;




      
    
    </summary>
    
    
      <category term="notes" scheme="https://github.com/SauronLee/categories/notes/"/>
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
      <category term="Research Notes" scheme="https://github.com/SauronLee/tags/Research-Notes/"/>
    
  </entry>
  
  <entry>
    <title>[Fair is Better than Sensational] Notes</title>
    <link href="https://github.com/SauronLee/2020/12/10/arXiv-1905-09866-cs-notes/"/>
    <id>https://github.com/SauronLee/2020/12/10/arXiv-1905-09866-cs-notes/</id>
    <published>2020-12-10T05:50:15.000Z</published>
    <updated>2020-12-12T06:04:55.598Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Fair-is-Better-than-Sensational"><a href="#Fair-is-Better-than-Sensational" class="headerlink" title="Fair is Better than Sensational:"></a>Fair is Better than Sensational:</h2><p>Man is to Doctor as Woman is to Doctor</p><p><a href="http://arxiv.org/abs/1905.09866" target="_blank" rel="noopener">http://arxiv.org/abs/1905.09866</a></p><hr><p>静冈县过了十二月的第一个星期渐渐感到寒意。</p><p>19年的一篇Malvina Nissim的关于类比词的评价。</p><p>这篇文章中作者提到类比词的“words embedding”的评估方法存在很大的漏洞，在一些类比词的计算方法中都存在了人们介入的偏见，（A:B::C:D）B不能等于D的限制 Mikolov et al. (2013)中存在偏差：</p><blockquote><p>simr(a:b,c:d) = simr(b:a,d:c) </p><p>simr(a:b,c:d) = simr(c:d,a:b) </p><p>simr(a:b,c:d) ̸= simr(a:b,d:c) </p><p> simr(a:b,c:d) ̸= simr(a:d,c:b) </p><p>​                                                              -(<a href="http://arxiv.org/abs/1309.4035)P554" target="_blank" rel="noopener">http://arxiv.org/abs/1309.4035)P554</a></p></blockquote><ul><li><p>caucasian lawful black : criminal : 2.0 : lawful criminal defamation libel vigilante</p><p>​                                                             -    Manzini et al. (2019b) and Manzini et al. (2019c)</p></li></ul><p>在表格三中提取的一段数据，“白人守法而黑人犯罪”带有人们的偏见，然而是因为限制了index==1的输入，这是不公平的，因为“白人守法而黑人犯罪”和“黑人守法而白人犯罪”完全是相等的。</p><p>此外：</p><ul><li>man is to doctor as woman is to doctor* (where D == B)</li></ul><p>男人与女人都可以身为医生，而不是限制index==1后女人和护士画等号。</p><p>另外（当限制 D == C时）：</p><ul><li>short is to shorter as new is to new*, thus D == C</li></ul><p>在计算类比词的算法中也存在偏见，比如给出三个词求第四个词，第三个词给予了限制并带有人类的偏见（比如：3COSADD  Mikolov et al. (2013) 3COSMUL Levy and Goldberg (2014)）</p><p>文中提到Bolukbasi et al. (2016)计算类比词给予两个词（A：B）预测C，D并给与了cos（pi/3）的限制此方法消除了第三个词的限制但是也因为限制输入词而损失大量信息。</p><p>文中给了这样的一段狠话：</p><ul><li><p>even though this constraint is mentioned in the original paper (Mikolov et al. 2013)</p><p>and in follow-up work (Linzen 2016; Bolukbasi et al. 2016; Rogers, Drozd, and Li 2017;</p><p>Goldberg 2017; Schluter 2018), we believe this is not common knowledge in the field(analogy examples are still widely used), and even more so outside the field.</p></li></ul><p>个人想法：</p><p>对于词向量类比词的算法之前也有研究过还有东大16年发表过的<strong>3CosAvg</strong> (vector offset averaged over multiple pairs)和<strong>LRCos</strong> (supervised learning of the target class + cosine similarity to the <em>b</em> word)详细可以看下面的连接：</p><ul><li>（<a href="https://aclweb.org/aclwiki/Analogy_(State_of_the_art)）" target="_blank" rel="noopener">https://aclweb.org/aclwiki/Analogy_(State_of_the_art)）</a></li></ul><p>其实词嵌入模型计算的无非就是使相同语法位置结构的单词最小化点积或者说是最小化cos相似度，然而偏见算法并不能很好的表示一个词向量的好坏，他只能说明词向量有一种特性（这个特性是人们的偏见所附加的），更好更优质的词向量应当是作为一个Pre-train更好的去服务下游（decode）应用并产生更好的结果，研究方向应该如何解决多义词问题（比如刘知远老师在17年提出的的Sememe义原）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Fair-is-Better-than-Sensational&quot;&gt;&lt;a href=&quot;#Fair-is-Better-than-Sensational&quot; class=&quot;headerlink&quot; title=&quot;Fair is Better than Sensationa
      
    
    </summary>
    
    
      <category term="reading_notes" scheme="https://github.com/SauronLee/categories/reading-notes/"/>
    
    
      <category term="paper" scheme="https://github.com/SauronLee/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>統計学習方法ノート</title>
    <link href="https://github.com/SauronLee/2020/11/04/Lihang-ML-notes/"/>
    <id>https://github.com/SauronLee/2020/11/04/Lihang-ML-notes/</id>
    <published>2020-11-04T08:17:38.000Z</published>
    <updated>2021-03-26T20:08:58.635Z</updated>
    
    <content type="html"><![CDATA[<div class="row">    <embed src="/pdf/Statistics_notes.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
    
    <summary type="html">
    
      
      
        

	&lt;div class=&quot;row&quot;&gt;
    &lt;embed src=&quot;/pdf/Statistics_notes.pdf&quot; width=&quot;100%&quot; height=&quot;550&quot; type=&quot;application/pdf&quot;&gt;
	&lt;/div&gt;



      
    
    </summary>
    
    
      <category term="notes" scheme="https://github.com/SauronLee/categories/notes/"/>
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
  </entry>
  
  <entry>
    <title>basic math for ML</title>
    <link href="https://github.com/SauronLee/2020/10/31/basic-math-for-ML/"/>
    <id>https://github.com/SauronLee/2020/10/31/basic-math-for-ML/</id>
    <published>2020-10-30T17:27:20.000Z</published>
    <updated>2021-03-25T06:20:09.361Z</updated>
    
    <content type="html"><![CDATA[<div class="row">    <embed src="/pdf/basic_math_for_ML_notes.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
    
    <summary type="html">
    
      
      
        

	&lt;div class=&quot;row&quot;&gt;
    &lt;embed src=&quot;/pdf/basic_math_for_ML_notes.pdf&quot; width=&quot;100%&quot; height=&quot;550&quot; type=&quot;application/pdf&quot;&gt;
	&lt;/div&gt;



      
    
    </summary>
    
    
      <category term="notes" scheme="https://github.com/SauronLee/categories/notes/"/>
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
  </entry>
  
  <entry>
    <title>Sunannan 10,000 words</title>
    <link href="https://github.com/SauronLee/2020/10/16/Sunannan-10-000-words/"/>
    <id>https://github.com/SauronLee/2020/10/16/Sunannan-10-000-words/</id>
    <published>2020-10-16T12:20:01.000Z</published>
    <updated>2021-03-25T06:16:26.315Z</updated>
    
    <content type="html"><![CDATA[<div class="row">    <embed src="/pdf/Sunannan_1wwords.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
    
    <summary type="html">
    
      
      
        

	&lt;div class=&quot;row&quot;&gt;
    &lt;embed src=&quot;/pdf/Sunannan_1wwords.pdf&quot; width=&quot;100%&quot; height=&quot;550&quot; type=&quot;application/pdf&quot;&gt;
	&lt;/div&gt;



      
    
    </summary>
    
    
      <category term="notes" scheme="https://github.com/SauronLee/categories/notes/"/>
    
    
      <category term="english" scheme="https://github.com/SauronLee/tags/english/"/>
    
  </entry>
  
  <entry>
    <title>EM Arithmetic by Zou</title>
    <link href="https://github.com/SauronLee/2019/10/05/EM-Arithmetic-by-Zou/"/>
    <id>https://github.com/SauronLee/2019/10/05/EM-Arithmetic-by-Zou/</id>
    <published>2019-10-05T04:11:08.000Z</published>
    <updated>2019-12-25T05:32:59.552Z</updated>
    
    <content type="html"><![CDATA[<p>特徴：データー量が少ないとき、データーを欠くの時、例えば：Gauss混合モデル(GMM)</p><hr><p>アルゴリズム例：Gauss混合モデル(GMM)<br>既知：人々の身長を知っだ、性別を予測する<br>h1,h2,h3,…,h<br>男の人:Gauss(u1,sigma1) n1/n = P1<br>女の人:Gauss(u２,sigma２) n２/n = P２<br>hi = P1_i <em> Gauss(u1_i,sigma1) + P２_i </em> Gauss(u２_i,sigma２)</p><hr><p>GMM-EM</p><script src="https://gist.github.com/SauronLee/e6b2a22e5ded4e9fa8aaa8c30bf2f7ee.js"></script><p><img src="/images/A-Z_ML/272.png" alt="EM"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;特徴：データー量が少ないとき、データーを欠くの時、例えば：Gauss混合モデル(GMM)&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;アルゴリズム例：Gauss混合モデル(GMM)&lt;br&gt;既知：人々の身長を知っだ、性別を予測する&lt;br&gt;h1,h2,h3,…,h&lt;br&gt;男の人:Gauss(u1,
      
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning Certificate by Coursera</title>
    <link href="https://github.com/SauronLee/2019/09/30/Deep-Learning-Certificate-by-Coursera/"/>
    <id>https://github.com/SauronLee/2019/09/30/Deep-Learning-Certificate-by-Coursera/</id>
    <published>2019-09-30T07:35:03.000Z</published>
    <updated>2019-12-25T05:26:54.395Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/NXkwpX7.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/NXkwpX7.png&quot; alt&gt;&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="news" scheme="https://github.com/SauronLee/categories/news/"/>
    
    
  </entry>
  
  <entry>
    <title>NLP of R by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/15/NLP-of-R-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/15/NLP-of-R-by-A-Z/</id>
    <published>2019-09-14T17:09:21.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/A-Z_ML/272.png" alt="テキスト"></p><hr><ul><li>テキストを利用して、テキストが積極的か消極的かを予測します。</li><li>左の部分は段落にコンマできりました、右の方うがスペースを使って段落を引き。普通の時私たちがよくコンマを使います段落でも色々な状態であっだので、もしコンマを段落を区別すれば紛らわしくしまっだ、だから左の部分はここで我々は左のテキストを使います、</li></ul><script src="https://gist.github.com/SauronLee/e5cb61a2fb628954e353a7ca6193c3e5.js"></script><hr><ul><li>databset-tape of word model</li></ul><p><img src="/images/A-Z_ML/272.png" alt></p><hr><p>1, 大文字が子文字に転換する(map=マッピング)<br>corpus = tm_map(corpus, content_transformer(tolower))</p><ul><li>corpusを検査（corpusが超複雑だ）</li></ul><pre><code>as.character(corpus[[1]])[1] &quot;wow... loved this place.&quot;</code></pre><p>2, ナンバーを抜いて<br>corpus = tm_map(corpus, removeNumbers)<br>3, 句読点を削除して<br>corpus = tm_map(corpus, removePunctuation)<br>4, きょじを削除して<br>corpus = tm_map(corpus, removeWords, stopwords())<br>5, 全部の単語を語根に転換して<br>corpus = tm_map(corpus, stemDocument)<br>6, 最後は余計なスペースを削除して(まばらになっだ)<br>corpus = tm_map(corpus, stripWhitespace)<br>7,疎らなマトリクスを作ります<br>dtm = DocumentTermMatrix(corpus)<br>dtm<br>&lt;<documenttermmatrix (documents: 1000, terms: 1577)>&gt;<br>＃ここでゼロではないの数割るゼロの数<br>＃Sparsity＝空疎性、大きすぎだから、百パーセントになっだ<br>Non-/sparse entries: 5435/1571565<br>Sparsity           : 100%<br>Maximal term length: 32<br>Weighting          : term frequency (tf)<br>＃ここでオレたち一番最大空疎を耐えられるな比率を書いて（もしその）<br>dtm = removeSparseTerms(dtm, 0.999)</documenttermmatrix></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/A-Z_ML/272.png&quot; alt=&quot;テキスト&quot;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;テキストを利用して、テキストが積極的か消極的かを予測します。&lt;/li&gt;
&lt;li&gt;左の部分は段落にコンマできりました、右の方うがスペースを使って段落
      
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
      <category term="Data cleaning" scheme="https://github.com/SauronLee/tags/Data-cleaning/"/>
    
      <category term="R" scheme="https://github.com/SauronLee/tags/R/"/>
    
      <category term="NLP" scheme="https://github.com/SauronLee/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Thompson of R by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/14/Thompson-of-R-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/14/Thompson-of-R-by-A-Z/</id>
    <published>2019-09-14T09:35:37.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<script src="https://gist.github.com/SauronLee/71d18847f9d0a9dc5bbe3564c63f45bf.js"></script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;https://gist.github.com/SauronLee/71d18847f9d0a9dc5bbe3564c63f45bf.js&quot;&gt;&lt;/script&gt;


      
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
      <category term="R" scheme="https://github.com/SauronLee/tags/R/"/>
    
      <category term="Reinforcement Learning" scheme="https://github.com/SauronLee/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Thompson of Python by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/14/Thompson-of-Python-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/14/Thompson-of-Python-by-A-Z/</id>
    <published>2019-09-14T09:35:28.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<script src="https://gist.github.com/SauronLee/62fa94764ef0090f9d527026b801ba90.js"></script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;https://gist.github.com/SauronLee/62fa94764ef0090f9d527026b801ba90.js&quot;&gt;&lt;/script&gt;
      
    
    </summary>
    
    
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
      <category term="Python" scheme="https://github.com/SauronLee/tags/Python/"/>
    
      <category term="Reinforcement Learning" scheme="https://github.com/SauronLee/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Thompson by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/14/Thompson-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/14/Thompson-by-A-Z/</id>
    <published>2019-09-14T08:45:57.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/A-Z_ML/264.png" alt><br><img src="/images/A-Z_ML/265.png" alt><br><img src="/images/A-Z_ML/266.png" alt><br><img src="/images/A-Z_ML/267.png" alt><br><img src="/images/A-Z_ML/268.png" alt><br><img src="/images/A-Z_ML/269.png" alt><br><img src="/images/A-Z_ML/270.png" alt><br>Thompson 抽样算法 vs.置信区间上界算法<br><img src="/images/A-Z_ML/271.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/A-Z_ML/264.png&quot; alt&gt;&lt;br&gt;&lt;img src=&quot;/images/A-Z_ML/265.png&quot; alt&gt;&lt;br&gt;&lt;img src=&quot;/images/A-Z_ML/266.png&quot; alt&gt;&lt;br&gt;&lt;img src=&quot;/
      
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
  </entry>
  
  <entry>
    <title>UCB of R by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/14/UCB-of-R-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/14/UCB-of-R-by-A-Z/</id>
    <published>2019-09-14T04:04:11.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<hr><p><img src="/images/A-Z_ML/259.png" alt></p><p><img src="/images/A-Z_ML/260.png" alt></p><script src="https://gist.github.com/SauronLee/2ed74170dc1af00aad6674178d65b1b5.js"></script><p><img src="/images/A-Z_ML/262.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;p&gt;&lt;img src=&quot;/images/A-Z_ML/259.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/A-Z_ML/260.png&quot; alt&gt;&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/Sauron
      
    
    </summary>
    
    
    
      <category term="Reinforcement Learning" scheme="https://github.com/SauronLee/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>UCB of Python by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/14/UCB-of-Python-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/14/UCB-of-Python-by-A-Z/</id>
    <published>2019-09-14T04:04:04.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<hr><p><img src="/images/A-Z_ML/259.png" alt></p><p><img src="/images/A-Z_ML/260.png" alt></p><script src="https://gist.github.com/SauronLee/04fa41594e98eff9482d83e16ec19335.js"></script><hr><p><img src="/images/A-Z_ML/261.png" alt></p><script src="https://gist.github.com/SauronLee/3843d23660459dd0a44a65b8814dc284.js"></script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;p&gt;&lt;img src=&quot;/images/A-Z_ML/259.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/A-Z_ML/260.png&quot; alt&gt;&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/Sauron
      
    
    </summary>
    
    
    
      <category term="Reinforcement Learning" scheme="https://github.com/SauronLee/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>UCB by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/14/UCB-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/14/UCB-by-A-Z/</id>
    <published>2019-09-14T03:37:37.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/A-Z_ML/250.png" alt><br><img src="/images/A-Z_ML/251.png" alt><br><img src="/images/A-Z_ML/252.png" alt><br><img src="/images/A-Z_ML/253.png" alt><br><img src="/images/A-Z_ML/254.png" alt><br><img src="/images/A-Z_ML/255.png" alt><br><img src="/images/A-Z_ML/256.png" alt><br><img src="/images/A-Z_ML/257.png" alt><br><img src="/images/A-Z_ML/258.png" alt></p><ul><li>我们的收益在灰色区间之中</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/A-Z_ML/250.png&quot; alt&gt;&lt;br&gt;&lt;img src=&quot;/images/A-Z_ML/251.png&quot; alt&gt;&lt;br&gt;&lt;img src=&quot;/images/A-Z_ML/252.png&quot; alt&gt;&lt;br&gt;&lt;img src=&quot;/
      
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
      <category term="Reinforcement Learning" scheme="https://github.com/SauronLee/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>K-Means Clustering of R by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/14/K-Means-Clustering-of-R-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/14/K-Means-Clustering-of-R-by-A-Z/</id>
    <published>2019-09-13T15:47:23.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/A-Z_ML/232.png" alt="issue"></p><ul><li>数据是商场的用户购买评分，越高用户花的钱越多，帮助商场把用户分群，那样的客户更愿意消费</li></ul><h2 id><a href="#" class="headerlink" title></a><script src="https://gist.github.com/SauronLee/30e18655a8f30377c01281a6a67b136f.js"></script></h2><pre><code>#每个用户被分到哪个组&gt; y_kmeans  [1] 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 4 2 5 2 4 5 [48] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 [95] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 3 1 3 5 3 1 3 1 3 5 3 1 3 1 3 1 3 1[142] 3 5 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3[189] 1 3 1 3 1 3 1 3 1 3 1 3</code></pre><hr><p><img src="/images/A-Z_ML/230.png" alt><br><img src="/images/A-Z_ML/231.png" alt></p><hr><p>kmeans {stats}    R Documentation<br>K-Means Clustering<br>Description<br>Perform k-means clustering on a data matrix.</p><p>Usage<br>kmeans(x, centers, iter.max = 10, nstart = 1,<br>       algorithm = c(“Hartigan-Wong”, “Lloyd”, “Forgy”,<br>                     “MacQueen”), trace=FALSE)</p><h2 id="S3-method-for-class-‘kmeans’"><a href="#S3-method-for-class-‘kmeans’" class="headerlink" title="S3 method for class ‘kmeans’"></a>S3 method for class ‘kmeans’</h2><p>fitted(object, method = c(“centers”, “classes”), …)<br>Arguments<br>x<br>numeric matrix of data, or an object that can be coerced to such a matrix (such as a numeric vector or a data frame with all numeric columns).</p><p>centers<br>either the number of clusters, say k, or a set of initial (distinct) cluster centres. If a number, a random set of (distinct) rows in x is chosen as the initial centres.</p><p>iter.max<br>the maximum number of iterations allowed.</p><p>nstart<br>if centers is a number, how many random sets should be chosen?</p><p>algorithm<br>character: may be abbreviated. Note that “Lloyd” and “Forgy” are alternative names for one algorithm.</p><p>object<br>an R object of class “kmeans”, typically the result ob of ob &lt;- kmeans(..).</p><p>method<br>character: may be abbreviated. “centers” causes fitted to return cluster centers (one for each input point) and “classes” causes fitted to return a vector of class assignments.</p><p>trace<br>logical or integer number, currently only used in the default method (“Hartigan-Wong”): if positive (or true), tracing information on the progress of the algorithm is produced. Higher values may produce more tracing information.</p><p>…<br>not used.</p><p>nstart<br>if centers is a number, how many random sets should be chosen?</p><h2 id="在开始时同时创建10组中心点然后选择一个最好的"><a href="#在开始时同时创建10组中心点然后选择一个最好的" class="headerlink" title="在开始时同时创建10组中心点然后选择一个最好的"></a>在开始时同时创建10组中心点然后选择一个最好的</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/A-Z_ML/232.png&quot; alt=&quot;issue&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据是商场的用户购买评分，越高用户花的钱越多，帮助商场把用户分群，那样的客户更愿意消费&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id&gt;&lt;a href=&quot;#&quot; cla
      
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
      <category term="R" scheme="https://github.com/SauronLee/tags/R/"/>
    
  </entry>
  
  <entry>
    <title>K-Means Clustering of Python by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/14/K-Means-Clustering-of-Python-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/14/K-Means-Clustering-of-Python-by-A-Z/</id>
    <published>2019-09-13T15:47:16.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/A-Z_ML/227.png" alt></p><ul><li>数据是商场的用户购买评分，越高用户花的钱越多，帮助商场把用户分群，那样的客户更愿意消费</li></ul><script src="https://gist.github.com/SauronLee/f33eea90a7d227f88884623dd37139dc.js"></script><p><img src="/images/A-Z_ML/228.png" alt><br><img src="/images/A-Z_ML/229.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/A-Z_ML/227.png&quot; alt&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据是商场的用户购买评分，越高用户花的钱越多，帮助商场把用户分群，那样的客户更愿意消费&lt;/li&gt;
&lt;/ul&gt;
&lt;script src=&quot;https://gist.gith
      
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
      <category term="Python" scheme="https://github.com/SauronLee/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>K-Means Clustering by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/13/K-Means-Clustering-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/13/K-Means-Clustering-by-A-Z/</id>
    <published>2019-09-13T14:40:54.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>K平均聚类算法 - 原理<br><img src="/images/A-Z_ML/112.png" alt><br><img src="/images/A-Z_ML/113.png" alt><br><img src="/images/A-Z_ML/114.png" alt><br><img src="/images/A-Z_ML/115.png" alt><br><img src="/images/A-Z_ML/116.png" alt><br><img src="/images/A-Z_ML/117.png" alt><br><img src="/images/A-Z_ML/118.png" alt></li><li>K-Means 随机初始化陷阱 Random Initialization Trap<br><img src="/images/A-Z_ML/119.png" alt><br><img src="/images/A-Z_ML/220.png" alt><br><img src="/images/A-Z_ML/221.png" alt></li><li>K++ 解决初始化陷阱<br><img src="/images/A-Z_ML/222.png" alt></li><li>K-Means 选择类的个数 Selecting The Number Of Clusters<br><img src="/images/A-Z_ML/223.png" alt></li><li>对每组数据的每个点到那组数据的中心点的距离求平方和WCSS，如果每组的组内平方和相加越小那么我们设置的这个中心点就越能表达这个的聚集集中性<br><img src="/images/A-Z_ML/224.png" alt></li><li>分成2组时整个组内平方WCSS有明显的下降<br><img src="/images/A-Z_ML/225.png" alt></li><li>虽然左边没有变动但是右边分成了两组所以整个WCSS又有降低<br><img src="/images/A-Z_ML/223.png" alt></li><li>如果样本集中有50个点我们把他分成50组，那么WCSS=0</li><li>手肘法则<br><img src="/images/A-Z_ML/226.png" alt></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;K平均聚类算法 - 原理&lt;br&gt;&lt;img src=&quot;/images/A-Z_ML/112.png&quot; alt&gt;&lt;br&gt;&lt;img src=&quot;/images/A-Z_ML/113.png&quot; alt&gt;&lt;br&gt;&lt;img src=&quot;/images/A-Z_ML/114.pn
      
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
  </entry>
  
  <entry>
    <title>Evaluating Classification Models Performance by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/13/Evaluating-Classification-Models-Performance-of-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/13/Evaluating-Classification-Models-Performance-of-by-A-Z/</id>
    <published>2019-09-13T09:23:51.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="通常时"><a href="#通常时" class="headerlink" title="通常时"></a>通常时</h1><ul><li>伪阳性和伪阴性 False Positives &amp; False Negatives(也叫做一型错误和二型错误)</li><li>也就是错误的负数和错误的正数</li></ul><p><img src="/images/A-Z_ML/101.png" alt></p><ul><li><p>-#2为伪阳性错误，#3为伪阴性错误，在生活中伪阳性错误更为严重，（如果一个艾滋病人我们利用血清等预判他有艾滋病时虽然严重但是他顶多会慌张一段时间然后再次检测从而排除，然而当出现伪阳性时那么一个病毒携带者评定没有艾滋病会导致艾滋病的传播）<br><img src="/images/A-Z_ML/102.png" alt></p></li><li><p>Confusion Matrix</p></li></ul><p><img src="/images/A-Z_ML/103.png" alt></p><h1 id="特殊时"><a href="#特殊时" class="headerlink" title="特殊时"></a>特殊时</h1><ul><li>Confusion Matrix 混淆矩阵虽然可以很好的反映出模型的成功率但是由于过于简单所以不能告诉我们很多细节。</li><li><p>准确率悖论 Accuracy Paradox<br><img src="/images/A-Z_ML/104.png" alt><br><img src="/images/A-Z_ML/105.png" alt></p></li><li><p>累计准确曲线 CAP Curve</p></li><li><p>我们把最好的模型叫做Crystal Ball，因为它可以预知未来，我们知道人群中会有10%的客户会购买我们的产品，而这个模型预测成功了这个10000个回去购买的用户，也就是说我们只给这10%的用户做广告，而这10%的用户正好都购买了我们的产品<br><img src="/images/A-Z_ML/108.png" alt><br><img src="/images/A-Z_ML/106.png" alt><br><img src="/images/A-Z_ML/107.png" alt></p></li><li><p>累计准确曲线分析 CAP Curve Analysis</p></li><li>越接近一越好，越接近零越差<br><img src="/images/A-Z_ML/109.png" alt></li><li>模型评估（注意：too good 为不正常这种时候好的有点超乎寻常，比如：1，自变量与因变量之间有某种因果关系的时候会出现，在例子中打电话次数与购买次数成因果关系的时候那么这种自变量必须从样本里剔除。2，过度拟合，3，建模的非常好超乎寻常的好）<br><img src="/images/A-Z_ML/110.png" alt></li></ul><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><ol><li>每个模型的长处和不足是什么？<br><img src="/images/A-Z_ML/111.png" alt></li><li>对于每个不同的案例，我如何在这些模型中作出选择？</li></ol><ul><li>首先，需要判断您面对的是一个线性还是非线性的问题。</li><li>假如是线性的问题，应该选择逻辑回归（logistic regression）或者支持向量机SVM。</li><li><p>假如是非线性的问题，应该选择朴素贝叶斯（naive bayes），决策树（decision tree）或者是随机森林（random forest）。在接下来的课程中我们会讲到神经网络（neural network），也是一个十分强大的方法。</p></li><li><p>从实际操作的角度来说，可以大致遵循以下的规则：</p></li><li><p>假如想要给最终预测概率进行排序，应该选择逻辑回归（logistic regression）或是朴素贝叶斯（Naive Bayes）。举个例子：想要预测不同客户购买某项产品的概率，并将这些概率从大到小进行排序，以便锁定目标客户群。在这样的情形下，如果您的问题是线性的，应该运用逻辑回归（logistic regression）；假如您的问题是非线性的，应该选择朴素贝叶斯（naive bayes）模型。</p></li><li>假如想要预测每一个客户属于哪一个划分（segment），应该选择SVM。市场和客户群体的划分可以是已完成的市场调研或者集群分析（clustering）的结果。</li><li>假如想要非常直观地展示／阐述模型，那么决策树（Decision Tree）是最佳选择。</li><li>假如想要最好的模型的分类表现，并且不太在意模型的展示／阐述，那么随机森林（random forest）是不错的选择。</li></ul><ol><li>我如何提高每个模型的表现？</li></ol><p>在第10部分的第2章，我们会详细讲述如何调整模型参数，以提高模型的表现。总体来说，每个模型都有两种类型的的参数：</p><ul><li>可以被“学习”的参数，比如：线性回归中各个自变量的参数。</li><li>难以被学习的“超参数” （hyperparameter）。<br>一个好的“超参数“的例子是随机森林（random forest）算法中训练决策树的个数N。目前为止，我们应用它的默认值（比如500）。在第10部分的第2章当中我们会详细介绍如何调整、优化这些“超参数”。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;通常时&quot;&gt;&lt;a href=&quot;#通常时&quot; class=&quot;headerlink&quot; title=&quot;通常时&quot;&gt;&lt;/a&gt;通常时&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;伪阳性和伪阴性 False Positives &amp;amp; False Negatives(也叫做一型错误和二型错误)&lt;
      
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
  </entry>
  
  <entry>
    <title>Random Forest of R by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/13/Random-Forest-of-R-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/13/Random-Forest-of-R-by-A-Z/</id>
    <published>2019-09-13T09:03:14.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/A-Z_ML/100.png" alt></p><script src="https://gist.github.com/SauronLee/d3c2238ba1ea263551f096d64a5e594e.js"></script><hr><pre><code>&gt; # Predicting the Test set results&gt; y_pred = predict(classifier, newdata = test_set[-3])&gt; y_pred  2   4   5   9  12  18  19  20  22  29  32  34  35  38  45  46  48  52  66  69  74  75  82  84   0   0   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1  85  86  87  89 103 104 107 108 109 117 124 126 127 131 134 139 148 154 156 159 162 163 170 175   0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 176 193 199 200 208 213 224 226 228 229 230 234 236 237 239 241 255 264 265 266 273 274 281 286   0   0   0   0   1   1   1   0   1   0   0   1   1   0   0   1   0   0   1   1   1   1   1   1 292 299 302 305 307 310 316 324 326 332 339 341 343 347 353 363 364 367 368 369 372 373 380 383   1   0   0   0   1   0   0   1   0   1   0   1   0   1   1   0   0   1   0   0   1   0   1   0 389 392 395 400   1   1   0   1 Levels: 0 1&gt; # Making the Confusion Matrix&gt; cm = table(test_set[, 3], y_pred)&gt; cm   y_pred     0  1  0 59  5  1  9 27</code></pre><p><img src="/images/A-Z_ML/95.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/A-Z_ML/100.png&quot; alt&gt;&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/SauronLee/d3c2238ba1ea263551f096d64a5e594e.js&quot;&gt;&lt;/script&gt;

      
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
      <category term="R" scheme="https://github.com/SauronLee/tags/R/"/>
    
  </entry>
  
  <entry>
    <title>Random Forest of Python by A-Z</title>
    <link href="https://github.com/SauronLee/2019/09/13/Random-Forest-of-Python-by-A-Z/"/>
    <id>https://github.com/SauronLee/2019/09/13/Random-Forest-of-Python-by-A-Z/</id>
    <published>2019-09-13T08:39:44.000Z</published>
    <updated>2019-09-23T06:31:47.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/A-Z_ML/94.png" alt="issue"></p><pre><code># Random Forest Classification# Importing the librariesimport numpy as npimport matplotlib.pyplot as pltimport pandas as pd# Importing the datasetdataset = pd.read_csv(&#39;Social_Network_Ads.csv&#39;)X = dataset.iloc[:, [2, 3]].valuesy = dataset.iloc[:, 4].values# Splitting the dataset into the Training set and Test setfrom sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)# Feature Scalingfrom sklearn.preprocessing import StandardScalersc = StandardScaler()X_train = sc.fit_transform(X_train)X_test = sc.transform(X_test)# Fitting Random Forest to the Training setfrom sklearn.ensemble import RandomForestClassifierclassifier = RandomForestClassifier(n_estimators = 10, criterion = &#39;entropy&#39;, random_state = 0 )classifier.fit(X_train, y_train)# Predicting the Test set resultsy_pred = classifier.predict(X_test)# Making the Confusion Matrixfrom sklearn.metrics import confusion_matrixcm = confusion_matrix(y_test, y_pred)# Visualising the Training set resultsfrom matplotlib.colors import ListedColormapX_set, y_set = X_train, y_trainX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),             alpha = 0.75, cmap = ListedColormap((&#39;red&#39;, &#39;green&#39;)))plt.xlim(X1.min(), X1.max())plt.ylim(X2.min(), X2.max())for i, j in enumerate(np.unique(y_set)):    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],                c = ListedColormap((&#39;orange&#39;, &#39;blue&#39;))(i), label = j, s=15)plt.title(&#39;Random Forest (Training set)&#39;)plt.xlabel(&#39;Age&#39;)plt.ylabel(&#39;Estimated Salary&#39;)plt.legend()plt.show()# Visualising the Test set resultsfrom matplotlib.colors import ListedColormapX_set, y_set = X_test, y_testX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),             alpha = 0.75, cmap = ListedColormap((&#39;red&#39;, &#39;green&#39;)))plt.xlim(X1.min(), X1.max())plt.ylim(X2.min(), X2.max())for i, j in enumerate(np.unique(y_set)):    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],                c = ListedColormap((&#39;orange&#39;, &#39;blue&#39;))(i), label = j, s=15)plt.title(&#39;Random Forest (Test set)&#39;)plt.xlabel(&#39;Age&#39;)plt.ylabel(&#39;Estimated Salary&#39;)plt.legend()plt.show()</code></pre><p><img src="/images/A-Z_ML/95.png" alt="issue"><br><img src="/images/A-Z_ML/96.png" alt="issue"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/A-Z_ML/94.png&quot; alt=&quot;issue&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
# Random Forest Classification

# Importing the libraries
import numpy as n
      
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="https://github.com/SauronLee/tags/Machine-Learning/"/>
    
      <category term="Statistics" scheme="https://github.com/SauronLee/tags/Statistics/"/>
    
      <category term="Python" scheme="https://github.com/SauronLee/tags/Python/"/>
    
  </entry>
  
</feed>
