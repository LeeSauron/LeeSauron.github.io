<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Tag: Statistics | Sauron Lee‘blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="李笑然">
<meta name="keywords" content="Statistics;ML;FEND">
<meta property="og:type" content="website">
<meta property="og:title" content="Sauron Lee‘blog">
<meta property="og:url" content="https://github.com/SauronLee/tags/Statistics/page/4/index.html">
<meta property="og:site_name" content="Sauron Lee‘blog">
<meta property="og:description" content="李笑然">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Sauron Lee‘blog">
<meta name="twitter:description" content="李笑然">
  
    <link rel="alternate" href="/atom.xml" title="Sauron Lee‘blog" type="application/atom+xml">
  
  
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/styles.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>
</html>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class=""
                 href="/index.html">Home</a></li>
        
          <li><a class=""
                 href="/categories/math">Math</a></li>
        
          <li><a class=""
                 href="/categories/news">News</a></li>
        
          <li><a class=""
                 href="/categories/projects">Projects</a></li>
        
      </ul>

      
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
     
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h1 class="blog-title">Sauron Lee‘blog</h1>
  
    <p class="lead blog-description">Li xiaoran</p>
  
</div>

    <div class="row">
        <div class="col-sm-8 blog-main">
          
  
  
    
    
      
      
      <section class="archives-wrap">
        <div class="archive-year-wrap">
          <a href="/archives/2019" class="archive-year">2019</a>
        </div>
        <div class="archives">
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/08/20/statistics-by-HouPhD/">Statistics by HouPhD</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/08/20/statistics-by-HouPhD/" class="archive-article-date"><time datetime="2019-08-20T14:02:11.000Z" itemprop="datePublished">August 20th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="事件的概率-高中知识"><a href="#事件的概率-高中知识" class="headerlink" title="事件的概率(高中知识)"></a>事件的概率(高中知识)</h1><hr>
<h2 id="无放回类题目"><a href="#无放回类题目" class="headerlink" title="无放回类题目"></a>无放回类题目</h2><p><img src="/images/statisticsHouPhD/02.png" alt><br><img src="/images/statisticsHouPhD/03.png" alt><br><img src="/images/statisticsHouPhD/04.png" alt><br><img src="/images/statisticsHouPhD/05.png" alt></p>
<h2 id="有放回类题目"><a href="#有放回类题目" class="headerlink" title="有放回类题目"></a>有放回类题目</h2><p><img src="/images/statisticsHouPhD/06.png" alt><br><img src="/images/statisticsHouPhD/07.png" alt></p>
<h2 id="画图题目"><a href="#画图题目" class="headerlink" title="画图题目"></a>画图题目</h2><p><img src="/images/statisticsHouPhD/09.png" alt><br><img src="/images/statisticsHouPhD/08.png" alt><br><img src="/images/statisticsHouPhD/10.png" alt></p>
<h2 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h2><p><img src="/images/statisticsHouPhD/11.png" alt><br><img src="/images/statisticsHouPhD/12.png" alt><br><img src="/images/statisticsHouPhD/13.png" alt></p>
<h2 id="全概率公式"><a href="#全概率公式" class="headerlink" title="全概率公式"></a>全概率公式</h2><p><img src="/images/statisticsHouPhD/14.png" alt><br><img src="/images/statisticsHouPhD/15.png" alt><br><img src="/images/statisticsHouPhD/16.png" alt><br><img src="/images/statisticsHouPhD/17.png" alt></p>
<hr>
<h1 id="一维随机变量"><a href="#一维随机变量" class="headerlink" title="一维随机变量"></a>一维随机变量</h1><p><img src="/images/statisticsHouPhD/19.png" alt><br><img src="/images/statisticsHouPhD/20.png" alt><br><img src="/images/statisticsHouPhD/21.png" alt><br><img src="/images/statisticsHouPhD/22.png" alt><br><img src="/images/statisticsHouPhD/23.png" alt></p>
<ul>
<li><img src="/images/statisticsHouPhD/24.png" alt><br><img src="/images/statisticsHouPhD/25.png" alt></li>
<li>满足三个公式求函数中系数<br><img src="/images/statisticsHouPhD/26.png" alt><br><img src="/images/statisticsHouPhD/27.png" alt></li>
<li>求分布律<br><img src="/images/statisticsHouPhD/28.png" alt><br><img src="/images/statisticsHouPhD/29.png" alt><br><img src="/images/statisticsHouPhD/30.png" alt><br><img src="/images/statisticsHouPhD/31.png" alt><br><img src="/images/statisticsHouPhD/32.png" alt><br><img src="/images/statisticsHouPhD/33.png" alt></li>
<li>分布题型<br><img src="/images/statisticsHouPhD/34.png" alt><br><img src="/images/statisticsHouPhD/35.png" alt><br><img src="/images/statisticsHouPhD/36.png" alt><br><img src="/images/statisticsHouPhD/37.png" alt><br><img src="/images/statisticsHouPhD/38.png" alt></li>
</ul>

      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/08/19/statistics-by-Libaijian01/">Statistics by Libaijian</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/08/19/statistics-by-Libaijian01/" class="archive-article-date"><time datetime="2019-08-19T10:11:27.000Z" itemprop="datePublished">August 19th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="抽样种类"><a href="#抽样种类" class="headerlink" title="抽样种类"></a>抽样种类</h1><hr>
<h2 id="随机抽样"><a href="#随机抽样" class="headerlink" title="随机抽样"></a>随机抽样</h2><h3 id="简单随机抽样-Simple-Random-sampling"><a href="#简单随机抽样-Simple-Random-sampling" class="headerlink" title="简单随机抽样 Simple Random sampling"></a>简单随机抽样 Simple Random sampling</h3><p>Simple Random sampling<br>必须取得母体全体，才能够进行（困难）</p>
<h3 id="系统抽样-systematic-sampling"><a href="#系统抽样-systematic-sampling" class="headerlink" title="系统抽样 systematic sampling"></a>系统抽样 systematic sampling</h3><p>systematic sampling<br>将母体平均分成k个样本，然后进行样本抽取</p>
<h3 id="分层抽样-Stratified-sampling"><a href="#分层抽样-Stratified-sampling" class="headerlink" title="分层抽样 Stratified sampling"></a>分层抽样 Stratified sampling</h3><p>Stratified sampling<br>分层每层无交集（适用高中低差别大的样本）</p>
<h3 id="部落抽样-cluster-sampling"><a href="#部落抽样-cluster-sampling" class="headerlink" title="部落抽样 cluster sampling"></a>部落抽样 cluster sampling</h3><p>cluster sampling</p>
<h2 id="随机用一个部落为整体（不适用高中低差别大的样本）"><a href="#随机用一个部落为整体（不适用高中低差别大的样本）" class="headerlink" title="随机用一个部落为整体（不适用高中低差别大的样本）"></a>随机用一个部落为整体（不适用高中低差别大的样本）</h2><h2 id="非随机抽样"><a href="#非随机抽样" class="headerlink" title="非随机抽样"></a>非随机抽样</h2><h3 id="偶遇抽样-convenience-sampling"><a href="#偶遇抽样-convenience-sampling" class="headerlink" title="偶遇抽样 convenience sampling"></a>偶遇抽样 convenience sampling</h3><p>convenience sampling<br>最常用（比如地铁口发传单）最方便，市场的初步调查</p>
<h3 id="配额抽样query-sampling"><a href="#配额抽样query-sampling" class="headerlink" title="配额抽样query  sampling"></a>配额抽样query  sampling</h3><p>query  sampling<br>跟分层抽样区别为这个是人员分配的层</p>
<h3 id="主观抽样-judgmental-sampling"><a href="#主观抽样-judgmental-sampling" class="headerlink" title="主观抽样 judgmental sampling"></a>主观抽样 judgmental sampling</h3><p>judgmental sampling<br>已经对母体非常熟悉，抽取具有代表性的样本</p>
<h3 id="滚雪球抽样snowball-sampling"><a href="#滚雪球抽样snowball-sampling" class="headerlink" title="滚雪球抽样snowball sampling"></a>滚雪球抽样snowball sampling</h3><p>snowball sampling<br>用抽样人员的直线分支下去抽样</p>
<hr>
<h2 id="效度validity"><a href="#效度validity" class="headerlink" title="效度validity"></a>效度validity</h2><p>内部效度：可信度，可靠度<br>外部效度：结果的泛化程度</p>
<p>以偏概全<br>一叶知秋</p>
<h1 id="尺度定义"><a href="#尺度定义" class="headerlink" title="尺度定义"></a>尺度定义</h1><h2 id="名义尺度-nominal"><a href="#名义尺度-nominal" class="headerlink" title="名义尺度 nominal"></a>名义尺度 nominal</h2><p>性别，职业，学号（没有顺序，不具有大小的意义）</p>
<h2 id="顺序0rdinal"><a href="#顺序0rdinal" class="headerlink" title="顺序0rdinal"></a>顺序0rdinal</h2><p>名次，排序（有大小，有先后）</p>
<h2 id="区间尺度Interval"><a href="#区间尺度Interval" class="headerlink" title="区间尺度Interval"></a>区间尺度Interval</h2><p>等距的，没有固定的原点（温度，满意度调查评价：1分2分）</p>
<h3 id="李克特量表-likert"><a href="#李克特量表-likert" class="headerlink" title="李克特量表 likert"></a>李克特量表 likert</h3><p>问卷调查中最常用的去坚尺度<br>李克特量表：（非常满意 满意 普通 不满意）</p>
<h2 id="比率尺度Ratio"><a href="#比率尺度Ratio" class="headerlink" title="比率尺度Ratio"></a>比率尺度Ratio</h2><p>可以衡量差异的数值，有原点，可以进行运算，（分数）</p>
<h1 id="柴比雪夫不等式-Chebyshev-inequality"><a href="#柴比雪夫不等式-Chebyshev-inequality" class="headerlink" title="柴比雪夫不等式 Chebyshev inequality"></a>柴比雪夫不等式 Chebyshev inequality</h1><hr>
<h2 id="经验法则-empirical-law"><a href="#经验法则-empirical-law" class="headerlink" title="经验法则 empirical law"></a>经验法则 empirical law</h2><ul>
<li>百分比就是几率</li>
<li>必须是正态分布<br>mu为样本的平均值，sigema为标准差<script type="math/tex; mode=display">
[\mu -\sigma ，\mu +\sigma ，]\approx 68%
[\mu -2\sigma ，\mu +2\sigma ，]\approx 95%
[\mu -3\sigma ，\mu +3\sigma ，]\approx 99.7%</script></li>
</ul>
<h2 id="柴比雪夫不等式-Chebyshev-inequality-1"><a href="#柴比雪夫不等式-Chebyshev-inequality-1" class="headerlink" title="柴比雪夫不等式 Chebyshev inequality"></a>柴比雪夫不等式 Chebyshev inequality</h2><ul>
<li>不用必须是正态分布</li>
</ul>
<script type="math/tex; mode=display">
P(|X-\mu | \leq k \sigma )\geq 1-\frac{1}{k^{2}};k>1</script><p>列题：<br><img src="/images/statisticsstatisticsLibaijian/02.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/03.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/04.png" alt="issue"></p>
<h2 id="馬可夫不等式-markov"><a href="#馬可夫不等式-markov" class="headerlink" title="馬可夫不等式 markov"></a>馬可夫不等式 markov</h2><ul>
<li><p>$P(X\geq k)\leq \frac{E(X)}{k}$<br><img src="/images/statisticsstatisticsLibaijian/05.png" alt="issue"></p>
</li>
<li><p>柴比雪夫不等式單邊版特例<br>证明<br><img src="/images/statisticsstatisticsLibaijian/06.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/07.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/08png" alt="issue"></p>
</li>
</ul>
<h1 id="排列组合"><a href="#排列组合" class="headerlink" title="排列组合"></a>排列组合</h1><h2 id="乘法原理"><a href="#乘法原理" class="headerlink" title="乘法原理"></a>乘法原理</h2><p>总数的阶乘，总数中取所有数的概率（也就是说总数中每个数都可以随意搭配）<br>排列中如果只取m个数的话，那么其实总数中就多出来总数减m个的概率，这个时候要除以多出来的概率<br><img src="/images/statisticsstatisticsLibaijian/09.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/10.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/11.png" alt="issue"></p>
<h2 id="组合"><a href="#组合" class="headerlink" title="组合"></a>组合</h2><p>组合=排列（挑选出的数不分左右，前后，12和21是一样的）</p>
<ul>
<li><p>因为分子是不需要排列的所以除以排列数m阶乘<br><img src="/images/statisticsstatisticsLibaijian/12.png" alt="issue"></p>
</li>
<li><p>重复组合的问题<br><img src="/images/statisticsstatisticsLibaijian/13.png" alt="issue"></p>
</li>
<li>变换成公式标准形态<br><img src="/images/statisticsstatisticsLibaijian/14.png" alt="issue"><br>组合+乘法原理=排列</li>
</ul>
<h2 id="二项式定理和多项式定理"><a href="#二项式定理和多项式定理" class="headerlink" title="二项式定理和多项式定理"></a>二项式定理和多项式定理</h2><p><img src="/images/statisticsstatisticsLibaijian/15.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/16.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/17.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/18.png" alt="issue"></p>
<h2 id="几率"><a href="#几率" class="headerlink" title="几率"></a>几率</h2><p><img src="/images/statisticsstatisticsLibaijian/19.png" alt="issue"></p>
<h2 id="排容原理"><a href="#排容原理" class="headerlink" title="排容原理"></a>排容原理</h2><p><img src="/images/statisticsstatisticsLibaijian/20.png" alt="issue"></p>
<h2 id="独立事件"><a href="#独立事件" class="headerlink" title="独立事件"></a>独立事件</h2><p><img src="/images/statisticsstatisticsLibaijian/21.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/22.png" alt="issue"></p>
<h2 id="互斥事件"><a href="#互斥事件" class="headerlink" title="互斥事件"></a>互斥事件</h2><p><img src="/images/statisticsstatisticsLibaijian/23.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/24.png" alt="issue"></p>
<h2 id="贝叶斯"><a href="#贝叶斯" class="headerlink" title="贝叶斯"></a>贝叶斯</h2><p><img src="/images/statisticsstatisticsLibaijian/25.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/26.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/27.png" alt="issue"></p>
<h1 id="随机变数"><a href="#随机变数" class="headerlink" title="随机变数"></a>随机变数</h1><p><img src="/images/statisticsstatisticsLibaijian/28.png" alt="issue"><br><img src="/images/statisticsstatisticsLibaijian/29.png" alt="issue"></p>

      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/08/14/Apriori-of-Python-by-A-Z/">Apriori of Python by A-Z</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/08/14/Apriori-of-Python-by-A-Z/" class="archive-article-date"><time datetime="2019-08-14T01:35:10.000Z" itemprop="datePublished">August 14th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <a class="fancybox" href="/images/A-Z_ML/244.png" title="[/images/A-Z_ML/244.png] [img_caption]"><img src="/images/A-Z_ML/244.png" alt="[/images/A-Z_ML/244.png] [img_caption]">
<!-- ![issue](/images/A-Z_ML/244.png) -->
<ul>
<li>数据是商场的用户的消费详情</li>
</ul>
<script src="https://gist.github.com/SauronLee/c3482834d2cb1dbab83abeef32da9d9d.js"></script>

<hr>
<p>transactions = []<br>for i in range(0, 7501):<br>    transactions.append([str(dataset.values[i,j]) for j in range(0, 20)])</p>
<!-- ![issue](/images/A-Z_ML/245.png) -->
<h1 id="Visualising-the-results"><a href="#Visualising-the-results" class="headerlink" title="Visualising the results"></a>Visualising the results</h1><p>results = list(rules)<br>myResults = [list(x) for x in results]<br><!-- ![issue](/images/A-Z_ML/246.png) --></p>
<h2 id><a href="#" class="headerlink" title></a><a class="fancybox" href="/images/A-Z_ML/246.png" title="[/images/A-Z_ML/246.png] [img_caption]"><img src="/images/A-Z_ML/246.png" alt="[/images/A-Z_ML/246.png] [img_caption]"></a></h2></a>
      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/08/14/Apriori-of-R-by-A-Z/">Apriori of R by A-Z</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/08/14/Apriori-of-R-by-A-Z/" class="archive-article-date"><time datetime="2019-08-14T01:35:01.000Z" itemprop="datePublished">August 14th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/A-Z_ML/242.png" alt></p>
<ul>
<li>数据是商场的用户的消费详情</li>
</ul>
<script src="https://gist.github.com/SauronLee/e74ba75daa5b3e20486f961417c13566.js"></script>

<hr>
<pre><code>
&gt; dataset = read.csv(&#39;Market_Basket_Optimisation.csv&#39;, header = FALSE)
&gt; dataset = read.transactions(&#39;Market_Basket_Optimisation.csv&#39;, sep = &#39;,&#39;, rm.duplicates = TRUE)
distribution of transactions with duplicates:
# 重复一次出现在5行当中
1 
5 
&gt; summary(dataset)
transactions as itemMatrix in sparse format with
 7501 rows (elements/itemsets/transactions) and
 # 稀疏矩阵，1占0.03288973 其他都是0
 119 columns (items) and a density of 0.03288973 

most frequent items:
mineral water          eggs     spaghetti  french fries     chocolate       (Other) 
         1788          1348          1306          1282          1229         22405 

element (itemset/transaction) length distribution:
sizes
# 有1754笔交易只有1个产品
   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16   18   19   20 
1754 1358 1044  816  667  493  391  324  259  139  102   67   40   22   17    4    1    2    1 

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  1.000   2.000   3.000   3.914   5.000  20.000 

includes extended item information - examples:
             labels
1           almonds
2 antioxydant juice
3         asparagus
&gt; itemFrequencyPlot(dataset, topN = 10)
&gt; # Training Apriori on the dataset
&gt; rules = apriori(data = dataset, parameter = list(support = 0.004, confidence = 0.2))
Apriori

Parameter specification:
 confidence minval smax arem  aval originalSupport maxtime support minlen maxlen target   ext
        0.2    0.1    1 none FALSE            TRUE       5   0.004      1     10  rules FALSE

Algorithmic control:
 filter tree heap memopt load sort verbose
    0.1 TRUE TRUE  FALSE TRUE    2    TRUE

Absolute minimum support count: 30 

set item appearances ...[0 item(s)] done [0.00s].
set transactions ...[119 item(s), 7501 transaction(s)] done [0.01s].
sorting and recoding items ... [114 item(s)] done [0.00s].
creating transaction tree ... done [0.00s].
checking subsets of size 1 2 3 4 done [0.16s].
writing ... [811 rule(s)] done [0.00s].
creating S4 object  ... done [0.00s].
&gt; # Visualising the results
&gt; inspect(sort(rules, by = &#39;lift&#39;)[1:10])
     lhs                                            rhs             support     confidence
[1]  {light cream}                               =&gt; {chicken}       0.004532729 0.2905983 
[2]  {pasta}                                     =&gt; {escalope}      0.005865885 0.3728814 
[3]  {pasta}                                     =&gt; {shrimp}        0.005065991 0.3220339 
[4]  {eggs,ground beef}                          =&gt; {herb &amp; pepper} 0.004132782 0.2066667 
[5]  {whole wheat pasta}                         =&gt; {olive oil}     0.007998933 0.2714932 
[6]  {herb &amp; pepper,spaghetti}                   =&gt; {ground beef}   0.006399147 0.3934426 
[7]  {herb &amp; pepper,mineral water}               =&gt; {ground beef}   0.006665778 0.3906250 
[8]  {tomato sauce}                              =&gt; {ground beef}   0.005332622 0.3773585 
[9]  {mushroom cream sauce}                      =&gt; {escalope}      0.005732569 0.3006993 
[10] {frozen vegetables,mineral water,spaghetti} =&gt; {ground beef}   0.004399413 0.3666667 
     lift     count
[1]  4.843951 34   
[2]  4.700812 44   
[3]  4.506672 38   
[4]  4.178455 31   
[5]  4.122410 60   
[6]  4.004360 48   
[7]  3.975683 50   
[8]  3.840659 40   
[9]  3.790833 43   
[10] 3.731841 33   
&gt; 
&gt;
</code></pre><ul>
<li>每个产品出现的频率<br>itemFrequencyPlot(dataset, topN = 10)<br><img src="/images/A-Z_ML/242.png" alt></li>
</ul>
<p>transactions-class {arules}    R Documentation<br>Class transactions — Binary Incidence Matrix for Transactions<br>Description<br>The transactions class represents transaction data used for mining itemsets or rules. It is a direct extension of class itemMatrix to store a binary incidence matrix, item labels, and optionally transaction IDs and user IDs.</p>
<p>Details<br>Transactions can be created by coercion from lists containing transactions, but also from matrix and data.frames. However, you will need to prepare your data first (see coercion methods in the Methods Section and the Example Section below for details on the needed format).</p>
<p>Continuous variables: Association rule mining can only use items and does not work with continuous variables. Continuous variables need to be discretized first. An item resulting from discretization might be age&gt;18 and the column contains only TRUE or FALSE. Alternatively it can be a factor with levels age&lt;=18, 50=&gt;age&gt;18 and age&gt;50. These will be automatically converted into 3 items, one for each level. Have a look at the function discretize for automatic discretization.</p>
<p>Logical variables: A logical variable describing a person could be tall indicating if the person is tall using the values TRUE and FALSE. The fact that the person is tall would be encoded in the transaction containing the item tall while not tall persons would not have this item. Therefore, for logical variables, the TRUE value is converted into an item with the name of the variable and for the FALSE values no item is created.</p>
<p>Factors: The function also can convert columns with nominal values (i.e., factors) into a series of binary items (one for each level constructed as <code>variable name</code>=<code>level</code>). Note that nominal variables need to be encoded as factors (and not characters or numbers). This can be done with</p>
<p>data[,”a_nominal_var”] &lt;- factor(data[,”a_nominal_var”]).</p>
<p>Complete examples for how to prepare data can be found in the man pages for Income and Adult.</p>
<p>Transactions are represented as sparse binary matrices of class itemMatrix. If you work with several transaction sets at the same time, then the encoding (order of the items in the binary matrix) in the different sets is important. See itemCoding to learn how to encode and recode transaction sets.</p>
<p>Objects from the Class<br>Objects are created by coercion from objects of other classes (see Examples section) or by calls of the form new(“transactions”, …).</p>
<p>Slots<br>itemsetInfo:<br>a data.frame with one row per transaction (each transaction is considered an itemset). The data.frame can hold columns with additional information, e.g., transaction IDs or user IDs for each transaction. Note: this slot is inherited from class itemMatrix, but should be accessed in transactions with the method transactionInfo().</p>
<p>data:<br>object of class ngCMatrix to store the binary incidence matrix (see itemMatrix class)</p>
<p>itemInfo:<br>a data.frame to store item labels (see itemMatrix class)</p>
<p>Extends<br>Class itemMatrix, directly.</p>
<p>Methods<br>coerce<br>signature(from = “matrix”, to = “transactions”); produces a transactions data set from a binary incidence matrix. The column names are used as item labels and the row names are stores as transaction IDs.</p>
<p>coerce<br>signature(from = “transactions”, to = “matrix”); coerces the transactions data set into a binary incidence matrix.</p>
<p>coerce<br>signature(from = “list”, to = “transactions”); produces a transactions data set from a list. The names of the items in the list are used as item labels.</p>
<p>coerce<br>signature(from = “transactions”, to = “list”); coerces the transactions data set into a list of transactions. Each transaction is a vector of character strings (names of the contained items).</p>
<p>coerce<br>signature(from = “data.frame”, to = “transactions”); recodes the data frame containing only categorical variables (factors) or logicals all into a binary transaction data set. For binary variables only TRUE values are converted into items and the item label is the variable name. For factors, a dummy item for each level is automatically generated. Item labels are generated by concatenating variable names and levels with “=”. The original variable names and levels are stored in the itemInfo data frame as the components variables and levels. Note that NAs are ignored (i.e., do not generate an item).</p>
<p>coerce<br>signature(from = “transactions”, to = “data.frame”); represents the set of transactions in a printable form as a data.frame. Note that this does not reverse coercion from data.frame to transactions.</p>
<p>coerce<br>signature(from = “ngCMatrix”, to = “transactions”); Note that the data is stored transposed in the ngCMatrix. Items are stored as rows and transactions are columns!</p>
<p>dimnames, rownames, colnames<br>signature(x = “transactions”); returns row (transactionID) and column (item) names.</p>
<p>items<br>signature(x = “transactions”); returns the items in the transactions as an itemMatrix.</p>
<p>labels<br>signature(x = “transactions”); returns the labels for the itemsets in each transaction (see itemMatrix).</p>
<p>transactionInfo&lt;-<br>signature(x = “transactions”); replaces the transaction information with a new data.frame.</p>
<p>transactionInfo<br>signature(x = “transactions”); returns the transaction information as a data.frame.</p>
<p>show<br>signature(object = “transactions”)</p>
<p>summary<br>signature(object = “transactions”)</p>
<ul>
<li>apriori {arules}    R Documentation<br>Mining Associations with Apriori<br>Description<br>Mine frequent itemsets, association rules or association hyperedges using the Apriori algorithm. The Apriori algorithm employs level-wise search for frequent itemsets. The implementation of Apriori used includes some improvements (e.g., a prefix tree and item sorting).</li>
</ul>
<p>Usage<br>apriori(data, parameter = NULL, appearance = NULL, control = NULL)<br>Arguments<br>data<br>object of class transactions or any data structure which can be coerced into transactions (e.g., a binary matrix or data.frame).</p>
<p>parameter<br>object of class APparameter or named list. The default behavior is to mine rules with minimum support of 0.1, minimum confidence of 0.8, maximum of 10 items (maxlen), and a maximal time for subset checking of 5 seconds (maxtime).</p>
<p>appearance<br>object of class APappearance or named list. With this argument item appearance can be restricted (implements rule templates). By default all items can appear unrestricted.</p>
<p>control<br>object of class APcontrol or named list. Controls the algorithmic performance of the mining algorithm (item sorting, report progress (verbose), etc.)</p>

      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/08/10/Data-Preprocessing-by-Python/">Data Preprocessing by Python</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/08/10/Data-Preprocessing-by-Python/" class="archive-article-date"><time datetime="2019-08-10T11:08:27.000Z" itemprop="datePublished">August 10th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h2><script src="https://gist.github.com/SauronLee/d3f9b166dbfa5160de5411a0718c90b1.js"></script>

<p>command + i = helpeer</p>
<ul>
<li>Definition : Imputer(missing_values=”NaN”, strategy=”mean”, axis=0, verbose=0, copy=True)</li>
</ul>
<p>missing_values : integer or “NaN”, optional (default=”NaN”)<br>The placeholder for the missing values. All occurrences of missing_values will be imputed. For missing values encoded as np.nan, use the string value “NaN”.<br>strategy : string, optional (default=”mean”)<br>The imputation strategy.</p>
<p>If “mean”, then replace missing values using the mean along the axis.<br>If “median”, then replace missing values using the median along the axis.<br>If “most_frequent”, then replace missing using the most frequent value along the axis.<br>axis : integer, optional (default=0)<br>The axis along which to impute.</p>
<p>If axis=0, then impute along columns.<br>If axis=1, then impute along rows.<br>verbose : integer, optional (default=0)<br>Controls the verbosity of the imputer.<br>copy : boolean, optional (default=True)<br>If True, a copy of X will be created. If False, imputation will be done in-place whenever possible. Note that, in the following cases, a new copy will always be made, even if copy=False:</p>
<p>If X is not an array of floating values;<br>If X is sparse and missing_values=0;<br>If axis=0 and X is encoded as a CSR matrix;<br>If axis=1 and X is encoded as a CSC matrix.</p>
<ul>
<li>fit(X, y=None)</li>
</ul>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)<br>Input data, where n_samples is the number of samples and n_features is the number of features.</p>
<ul>
<li>Definition : OneHotEncoder(n_values=None, categorical_features=None, categories=None, sparse=True, dtype=np.float64, handle_unknown=’error’)</li>
</ul>
<p>Type : Present in sklearn.preprocessing._encoders module</p>
<p>categories : ‘auto’ or a list of lists/arrays of values, default=’auto’.<br>Categories (unique values) per feature:</p>
<p>‘auto’ : Determine categories automatically from the training data.<br>list : categories[i] holds the categories expected in the ith column. The passed categories should not mix strings and numeric values within a single feature, and should be sorted in case of numeric values.<br>The used categories can be found in the categories_ attribute.</p>
<p>sparse : boolean, default=True<br>Will return sparse matrix if set True else will return an array.<br>dtype : number type, default=np.float<br>Desired dtype of output.<br>handle_unknown : ‘error’ or ‘ignore’, default=’error’.<br>Whether to raise an error or ignore if an unknown categorical feature is present during transform (default is to raise). When this parameter is set to ‘ignore’ and an unknown category is encountered during transform, the resulting one-hot encoded columns for this feature will be all zeros. In the inverse transform, an unknown category will be denoted as None.<br>n_values : ‘auto’, int or array of ints, default=’auto’<br>Number of values per feature.</p>
<p>‘auto’ : determine value range from training data.</p>
<p>int : number of categorical values per feature.<br>Each feature value should be in range(n_values)</p>
<p>array : n_values[i] is the number of categorical values in<br>X[:, i]. Each feature value should be in range(n_values[i])</p>
<p>Deprecated since version 0.20: The n_values keyword was deprecated in version 0.20 and will be removed in 0.22. Use categories instead.</p>
<p>categorical_features : ‘all’ or array of indices or mask, default=’all’<br>Specify what features are treated as categorical.</p>
<p>‘all’: All features are treated as categorical.<br>array of indices: Array of categorical feature indices.<br>mask: Array of length n_features and with dtype=bool.<br>Non-categorical features are always stacked to the right of the matrix.</p>
<p>Deprecated since version 0.20: The categorical_features keyword was deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.</p>
<h2 id="特征缩放-Feature-Scaling"><a href="#特征缩放-Feature-Scaling" class="headerlink" title="特征缩放 Feature Scaling"></a>特征缩放 Feature Scaling</h2><ul>
<li>因为两个特征向量之间的差异可以用欧氏距离来表示（勾股定理），如果任意一个特征向量过于巨大那么距离大差异就会更偏向特征值巨大的量，甚至完全取决于这个量，于是就需要缩放到一个数量级上</li>
<li>特征缩放 Feature Scaling后某些模型收敛会快很多，比如决策树算法（枝干过长）</li>
<li><p>特征缩放方法：<br><img src="/images/A-Z_ML/01.png" alt></p>
</li>
<li><p>是否需要对虚拟变量进行特征缩放。答：不一定，要根据模型结果。</p>
</li>
<li>是否需要对因变量y进行特征缩放？答：不一定，如果y为分类则不需要，如果y为连续则需要（线性回归）。</li>
</ul>
<pre><code># Feature Scaling
from sklearn.preprocessing import StandardScaler
sc_XStandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)
</code></pre>
      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/08/10/Data-Preprocessing-by-R/">Data Preprocessing by R</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/08/10/Data-Preprocessing-by-R/" class="archive-article-date"><time datetime="2019-08-10T11:08:09.000Z" itemprop="datePublished">August 10th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h2><script src="https://gist.github.com/SauronLee/d07b84f9caefd89dbc3f76a943bd8166.js"></script>

<ul>
<li>因子数据类型（有序因子&amp;无序因子），可以代替Python中的OneHotEncoder</li>
</ul>
<p>Usage<br>factor(x = character(), levels, labels = levels,<br>       exclude = NA, ordered = is.ordered(x), nmax = NA)</p>
<p>ordered(x, …)</p>
<p>is.factor(x)<br>is.ordered(x)</p>
<p>as.factor(x)<br>as.ordered(x)</p>
<p>addNA(x, ifany = FALSE)<br>Arguments<br>x<br>a vector of data, usually taking a small number of distinct values.</p>
<p>levels<br>an optional vector of the unique values (as character strings) that x might have taken. The default is the unique set of values taken by as.character(x), sorted into increasing order of x. Note that this set can be specified as smaller than sort(unique(x)).</p>
<p>labels<br>either an optional character vector of labels for the levels (in the same order as levels after removing those in exclude), or a character string of length 1. Duplicated values in labels can be used to map different values of x to the same factor level.</p>
<p>exclude<br>a vector of values to be excluded when forming the set of levels. This may be factor with the same level set as x or should be a character.</p>
<p>ordered<br>logical flag to determine if the levels should be regarded as ordered (in the order given).</p>
<p>nmax<br>an upper bound on the number of levels; see ‘Details’.</p>
<p>…<br>(in ordered(.)): any of the above, apart from ordered itself.</p>
<p>ifany<br>only add an NA level if it is used, i.e. if any(is.na(x)).</p>
<h2 id="Splitting-the-Dataset-into-the-Training-set-and-Test-set"><a href="#Splitting-the-Dataset-into-the-Training-set-and-Test-set" class="headerlink" title="Splitting the Dataset into the Training set and Test set"></a>Splitting the Dataset into the Training set and Test set</h2><pre><code># Data Preprocessing Template

# Importing the dataset
dataset = read.csv(&#39;Data.csv&#39;)
# dataset = dataset[, 2:3]

# Splitting the dataset into the Training set and Test set
# R语言安装packages
# install.packages(&#39;caTools&#39;)
# library(caTools) = 在packages里面打钩，推荐用library(caTools) 
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# split == TRUE为random出来的数据
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)

# Feature Scaling
# training_set[, 2:3] = scale(training_set[, 2:3])
# test_set[, 2:3] = scale(test_set[, 2:3])
</code></pre><ul>
<li>set.seed<br>Random Number Generation</li>
</ul>
<p>Usage<br>.Random.seed &lt;- c(rng.kind, n1, n2, \dots)</p>
<p>RNGkind(kind = NULL, normal.kind = NULL, sample.kind = NULL)<br>RNGversion(vstr)<br>set.seed(seed, kind = NULL, normal.kind = NULL, sample.kind = NULL)<br>Arguments<br>kind<br>character or NULL. If kind is a character string, set R’s RNG to the kind desired. Use “default” to return to the R default. See ‘Details’ for the interpretation of NULL.</p>
<p>normal.kind<br>character string or NULL. If it is a character string, set the method of Normal generation. Use “default” to return to the R default. NULL makes no change.</p>
<p>sample.kind<br>character string or NULL. If it is a character string, set the method of discrete uniform generation (used in sample, for instance). Use “default” to return to the R default. NULL makes no change.</p>
<p>seed<br>a single value, interpreted as an integer, or NULL (see ‘Details’).</p>
<p>vstr<br>a character string containing a version number, e.g., “1.6.2”. The default RNG configuration of the current R version is used if vstr is greater than the current version.</p>
<p>rng.kind<br>integer code in 0:k for the above kind.</p>
<p>n1, n2, …<br>integers. See the details for how many are required (which depends on rng.kind).</p>
<ul>
<li>sample.split<br>Split Data into Test and Train Set</li>
</ul>
<p>Usage<br> sample.split( Y, SplitRatio = 2/3, group = NULL )<br>Arguments<br>Y<br>Vector of data labels. If there are only a few labels (as is expected) than relative ratio of data in both subsets will be the same.</p>
<p>SplitRatio<br>Splitting ratio:</p>
<p>if (0&lt;=SplitRatio&lt;1) then SplitRatio fraction of points from Y will be set toTRUE</p>
<p>if (SplitRatio==1) then one random point from Y will be set to TRUE</p>
<p>if (SplitRatio&gt;1) then SplitRatio number of points from Y will be set to TRUE</p>
<p>group<br>Optional vector/list used when multiple copies of each sample are present. In such a case group contains unique sample labels, marking all copies of the same sample with the same label, and the function tries to place all copies in either train or test subset. If provided than has to have the same length as Y.</p>
<h1 id="特征缩放-Feature-Scaling"><a href="#特征缩放-Feature-Scaling" class="headerlink" title="特征缩放 Feature Scaling"></a>特征缩放 Feature Scaling</h1><ul>
<li>因为两个特征向量之间的差异可以用欧氏距离来表示（勾股定理），如果任意一个特征向量过于巨大那么距离大差异就会更偏向特征值巨大的量，甚至完全取决于这个量，于是就需要缩放到一个数量级上</li>
<li>特征缩放 Feature Scaling后某些模型收敛会快很多，比如决策树算法（枝干过长）</li>
<li><p>特征缩放方法：<br><img src="/images/A-Z_ML/01.png" alt></p>
</li>
<li><p>是否需要对虚拟变量进行特征缩放？答：不一定，要根据模型结果。</p>
</li>
<li>是否需要对因变量y进行特征缩放？答：不一定，如果y为分类则不需要，如果y为连续则需要（线性回归）。</li>
<li>在R里factor属于单独的类型不属于数字它属于分类的一个数据类型</li>
</ul>
<pre><code># Feature Scaling
training_set[,2:3] = scale(training_set[,2:3])
test_set[,2:3] = scale(test_set[,2:3])
</code></pre>
      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/07/14/Artificial-Neural-Networks-of-Python-by-A-Z/">Artificial Neural Networks of Python by A-Z</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/07/14/Artificial-Neural-Networks-of-Python-by-A-Z/" class="archive-article-date"><time datetime="2019-07-14T06:32:59.000Z" itemprop="datePublished">July 14th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <script src="https://gist.github.com/SauronLee/071e1a959a04484f9d80d8362ec4a2cd.js"></script>
      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/07/13/CART-of-R-by-A-Z/">Decision Tree Classifier of R  by A-Z</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/07/13/CART-of-R-by-A-Z/" class="archive-article-date"><time datetime="2019-07-13T07:34:29.000Z" itemprop="datePublished">July 13th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/A-Z_ML/88.png" alt></p>
<ul>
<li>因为决策树用的是切线切割没有用到欧式距离所以不需要进行特征缩放</li>
</ul>
<script src="https://gist.github.com/SauronLee/5550de72b8e9ab228abb30178fe5dbb6.js"></script>

<hr>
<pre><code>
&gt; View(dataset)
&gt; y_pred
  2   4   5   9  12  18  19  20  22  29  32  34  35  38  45  46  48  52  66  69  74  75  82  84 
  0   0   0   0   0   0   1   1   0   0   1   0   1   0   0   0   0   0   0   0   1   0   0   1 
 85  86  87  89 103 104 107 108 109 117 124 126 127 131 134 139 148 154 156 159 162 163 170 175 
  0   1   0   0   1   1   0   1   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0 
176 193 199 200 208 213 224 226 228 229 230 234 236 237 239 241 255 264 265 266 273 274 281 286 
  0   0   0   0   1   1   1   0   1   0   0   1   1   0   1   1   0   0   1   1   1   1   1   1 
292 299 302 305 307 310 316 324 326 332 339 341 343 347 353 363 364 367 368 369 372 373 380 383 
  1   0   0   0   1   0   0   1   0   1   0   1   0   1   1   0   0   1   1   0   1   0   1   1 
389 392 395 400 
  1   1   0   1 
Levels: 0 1

&gt; cm
   y_pred
     0  1
  0 53 11
  1  6 30
</code></pre><p><img src="/images/A-Z_ML/89.png" alt><br><img src="/images/A-Z_ML/90.png" alt><br><img src="/images/A-Z_ML/91.png" alt></p>

      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/07/13/CART-of-Python-by-A-Z/">Decision Tree Classifier of Python by A-Z</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/07/13/CART-of-Python-by-A-Z/" class="archive-article-date"><time datetime="2019-07-13T07:34:19.000Z" itemprop="datePublished">July 13th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/A-Z_ML/85.png" alt></p>
<script src="https://gist.github.com/SauronLee/ef680bf345a816817042c7acf0503a39.js"></script>

<ul>
<li>由于过度拟合所以预测的非常差</li>
</ul>
<p><img src="/images/A-Z_ML/84.png" alt><br><img src="/images/A-Z_ML/86.png" alt></p>

      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/07/13/Bayes-Theorem-by-A-Z/">Bayes Theorem by A-Z</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/07/13/Bayes-Theorem-by-A-Z/" class="archive-article-date"><time datetime="2019-07-13T05:41:36.000Z" itemprop="datePublished">July 13th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/A-Z_ML/64.png" alt></p>
<ul>
<li>P(A)是先验概率P(A|B)是后验概率</li>
<li>B在朴素贝叶斯的分类器当中叫做特征，所以P(B)和P(A|B)不完全叫概率而叫做似然<br><img src="/images/A-Z_ML/65.png" alt></li>
<li>Plane Attack<br><img src="/images/A-Z_ML/66.png" alt><br><img src="/images/A-Z_ML/67.png" alt><br><img src="/images/A-Z_ML/68.png" alt><br><img src="/images/A-Z_ML/69.png" alt><br><img src="/images/A-Z_ML/70.png" alt><br><img src="/images/A-Z_ML/71.png" alt><br><img src="/images/A-Z_ML/72.png" alt><br><img src="/images/A-Z_ML/73.png" alt><br><img src="/images/A-Z_ML/74.png" alt><br><img src="/images/A-Z_ML/75.png" alt></li>
<li>缺少似然会降低计算量用于估计<br><img src="/images/A-Z_ML/76.png" alt></li>
</ul>

      
    </div>
  </header>
</article>


  
  
    </div></section>
  


  <div id="page-nav">
    <nav><ul class="pagination"><li><a class="page-prev" rel="prev" href="/tags/Statistics/page/3/"><i class="fa fa-chevron-left"></i> Prev</a></li><li><a class="page-number" href="/tags/Statistics/">1</a></li><li><a class="page-number" href="/tags/Statistics/page/2/">2</a></li><li><a class="page-number" href="/tags/Statistics/page/3/">3</a></li><li class="active"><span class="page-number">4</span></li><li><a class="page-number" href="/tags/Statistics/page/5/">5</a></li><li><a class="page-number" href="/tags/Statistics/page/6/">6</a></li><li><a class="page-next" rel="next" href="/tags/Statistics/page/5/">Next <i class="fa fa-chevron-right"></i></a></li></ul></nav>
  </div>


        </div>
        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
          
  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <p> Domain Tags Machine Learning, Deep Learning,  Front End Development, iOS Development, Statistics， <em>Python</em>, <em>R</em>, <em>Flutter</em>, <em>Swift</em>, <em>JavaScript</em>.</p>

</div>


  
  <div class="sidebar-module">
    <h4>Categories</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/math/">math</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/news/">news</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/project/">project</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/projects/">projects</a><span class="sidebar-module-list-count">5</span></li></ul>
  </div>




  
  <div class="sidebar-module">
    <h4>Tags</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/ANN/">ANN</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Calculus/">Calculus</a><span class="sidebar-module-list-count">6</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Computer-Vision/">Computer Vision</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Data-cleaning/">Data cleaning</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Deep-Learning/">Deep Learning</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/JavaScript/">JavaScript</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Linear-Algebra/">Linear Algebra</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Machine-Learning/">Machine Learning</a><span class="sidebar-module-list-count">51</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/NLP/">NLP</a><span class="sidebar-module-list-count">5</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Python/">Python</a><span class="sidebar-module-list-count">22</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/R/">R</a><span class="sidebar-module-list-count">15</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Reinforcement-Learning/">Reinforcement Learning</a><span class="sidebar-module-list-count">6</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Statistics/">Statistics</a><span class="sidebar-module-list-count">52</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/english/">english</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/git/">git</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/leetcode/">leetcode</a><span class="sidebar-module-list-count">5</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/linear-algebra/">linear algebra</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/nlp/">nlp</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/python/">python</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tag Cloud</h4>
    <p class="tagcloud">
      <a href="/tags/ANN/" style="font-size: 10px;">ANN</a> <a href="/tags/Calculus/" style="font-size: 15.56px;">Calculus</a> <a href="/tags/Computer-Vision/" style="font-size: 10px;">Computer Vision</a> <a href="/tags/Data-cleaning/" style="font-size: 13.33px;">Data cleaning</a> <a href="/tags/Deep-Learning/" style="font-size: 11.11px;">Deep Learning</a> <a href="/tags/JavaScript/" style="font-size: 13.33px;">JavaScript</a> <a href="/tags/Linear-Algebra/" style="font-size: 10px;">Linear Algebra</a> <a href="/tags/Machine-Learning/" style="font-size: 18.89px;">Machine Learning</a> <a href="/tags/NLP/" style="font-size: 14.44px;">NLP</a> <a href="/tags/Python/" style="font-size: 17.78px;">Python</a> <a href="/tags/R/" style="font-size: 16.67px;">R</a> <a href="/tags/Reinforcement-Learning/" style="font-size: 15.56px;">Reinforcement Learning</a> <a href="/tags/Statistics/" style="font-size: 20px;">Statistics</a> <a href="/tags/english/" style="font-size: 10px;">english</a> <a href="/tags/git/" style="font-size: 11.11px;">git</a> <a href="/tags/leetcode/" style="font-size: 14.44px;">leetcode</a> <a href="/tags/linear-algebra/" style="font-size: 12.22px;">linear algebra</a> <a href="/tags/nlp/" style="font-size: 10px;">nlp</a> <a href="/tags/python/" style="font-size: 10px;">python</a>
    </p>
  </div>


  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2020/10/">October 2020</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/10/">October 2019</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/09/">September 2019</a><span class="sidebar-module-list-count">30</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/08/">August 2019</a><span class="sidebar-module-list-count">20</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/07/">July 2019</a><span class="sidebar-module-list-count">11</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/06/">June 2019</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/05/">May 2019</a><span class="sidebar-module-list-count">6</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/02/">February 2019</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/08/">August 2018</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/05/">May 2018</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/04/">April 2018</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/03/">March 2018</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/02/">February 2018</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/12/">December 2017</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/10/">October 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/08/">August 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/06/">June 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/05/">May 2017</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/05/">May 2016</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="/2020/10/26/NLP-base-of-Greedy-notes/">NLP base of Greedy notes</a>
        </li>
      
        <li>
          <a href="/2020/10/20/Bayesian-Statistics-Notes-01/">Prof.Yeh Benson Statistics Notes</a>
        </li>
      
        <li>
          <a href="/2020/10/16/Sunannan-10-000-words/">Sunannan 10,000 words</a>
        </li>
      
        <li>
          <a href="/2019/10/05/EM-Arithmetic-by-Zou/">EM Arithmetic by Zou</a>
        </li>
      
        <li>
          <a href="/2019/09/30/Deep-Learning-Certificate-by-Coursera/">Deep Learning Certificate by Coursera</a>
        </li>
      
    </ul>
  </div>



        </div>
    </div>
  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2020 Sauron Lee<br>
       <!-- <a href="https://i.imgur.com/S8qHH1C.jpg" target="_blank"><b>@Sauron Lee</b></a>
       - -->
       <a href="https://github.com/SauronLee" target="_blank"> <b>GitHub</b></a>
       -
       <a href="https://leetcode.com/sauronlee/" target="_blank"> <b>Leetcode</b></a>
    </div>
  </div>
</footer>

  

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>

  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
