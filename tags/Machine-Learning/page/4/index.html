<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Tag: Machine Learning | Sauron Lee‘blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="李笑然">
<meta name="keywords" content="Statistics;ML;FEND">
<meta property="og:type" content="website">
<meta property="og:title" content="Sauron Lee‘blog">
<meta property="og:url" content="https://github.com/SauronLee/tags/Machine-Learning/page/4/index.html">
<meta property="og:site_name" content="Sauron Lee‘blog">
<meta property="og:description" content="李笑然">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Sauron Lee‘blog">
<meta name="twitter:description" content="李笑然">
  
    <link rel="alternate" href="/atom.xml" title="Sauron Lee‘blog" type="application/atom+xml">
  
  
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/styles.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>
</html>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class=""
                 href="/index.html">Home</a></li>
        
          <li><a class=""
                 href="/categories/math">Math</a></li>
        
          <li><a class=""
                 href="/categories/news">News</a></li>
        
          <li><a class=""
                 href="/categories/projects">Projects</a></li>
        
      </ul>

      
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
     
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h1 class="blog-title">Sauron Lee‘blog</h1>
  
    <p class="lead blog-description">Li xiaoran</p>
  
</div>

    <div class="row">
        <div class="col-sm-8 blog-main">
          
  
  
    
    
      
      
      <section class="archives-wrap">
        <div class="archive-year-wrap">
          <a href="/archives/2019" class="archive-year">2019</a>
        </div>
        <div class="archives">
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/08/13/Naive-Bayes-of-python-by-A-Z/">Naive Bayes of python by A-Z</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/08/13/Naive-Bayes-of-python-by-A-Z/" class="archive-article-date"><time datetime="2019-08-13T06:57:44.000Z" itemprop="datePublished">August 13th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/A-Z_ML/77.png" alt></p>
<script src="https://gist.github.com/SauronLee/3b8d2be2ae591a894876efc4ec63acff.js"></script>

<p><img src="/images/A-Z_ML/78.png" alt><br><img src="/images/A-Z_ML/79.png" alt></p>

      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/08/10/Data-Preprocessing-by-Python/">Data Preprocessing by Python</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/08/10/Data-Preprocessing-by-Python/" class="archive-article-date"><time datetime="2019-08-10T11:08:27.000Z" itemprop="datePublished">August 10th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h2><script src="https://gist.github.com/SauronLee/d3f9b166dbfa5160de5411a0718c90b1.js"></script>

<p>command + i = helpeer</p>
<ul>
<li>Definition : Imputer(missing_values=”NaN”, strategy=”mean”, axis=0, verbose=0, copy=True)</li>
</ul>
<p>missing_values : integer or “NaN”, optional (default=”NaN”)<br>The placeholder for the missing values. All occurrences of missing_values will be imputed. For missing values encoded as np.nan, use the string value “NaN”.<br>strategy : string, optional (default=”mean”)<br>The imputation strategy.</p>
<p>If “mean”, then replace missing values using the mean along the axis.<br>If “median”, then replace missing values using the median along the axis.<br>If “most_frequent”, then replace missing using the most frequent value along the axis.<br>axis : integer, optional (default=0)<br>The axis along which to impute.</p>
<p>If axis=0, then impute along columns.<br>If axis=1, then impute along rows.<br>verbose : integer, optional (default=0)<br>Controls the verbosity of the imputer.<br>copy : boolean, optional (default=True)<br>If True, a copy of X will be created. If False, imputation will be done in-place whenever possible. Note that, in the following cases, a new copy will always be made, even if copy=False:</p>
<p>If X is not an array of floating values;<br>If X is sparse and missing_values=0;<br>If axis=0 and X is encoded as a CSR matrix;<br>If axis=1 and X is encoded as a CSC matrix.</p>
<ul>
<li>fit(X, y=None)</li>
</ul>
<p>X : {array-like, sparse matrix}, shape (n_samples, n_features)<br>Input data, where n_samples is the number of samples and n_features is the number of features.</p>
<ul>
<li>Definition : OneHotEncoder(n_values=None, categorical_features=None, categories=None, sparse=True, dtype=np.float64, handle_unknown=’error’)</li>
</ul>
<p>Type : Present in sklearn.preprocessing._encoders module</p>
<p>categories : ‘auto’ or a list of lists/arrays of values, default=’auto’.<br>Categories (unique values) per feature:</p>
<p>‘auto’ : Determine categories automatically from the training data.<br>list : categories[i] holds the categories expected in the ith column. The passed categories should not mix strings and numeric values within a single feature, and should be sorted in case of numeric values.<br>The used categories can be found in the categories_ attribute.</p>
<p>sparse : boolean, default=True<br>Will return sparse matrix if set True else will return an array.<br>dtype : number type, default=np.float<br>Desired dtype of output.<br>handle_unknown : ‘error’ or ‘ignore’, default=’error’.<br>Whether to raise an error or ignore if an unknown categorical feature is present during transform (default is to raise). When this parameter is set to ‘ignore’ and an unknown category is encountered during transform, the resulting one-hot encoded columns for this feature will be all zeros. In the inverse transform, an unknown category will be denoted as None.<br>n_values : ‘auto’, int or array of ints, default=’auto’<br>Number of values per feature.</p>
<p>‘auto’ : determine value range from training data.</p>
<p>int : number of categorical values per feature.<br>Each feature value should be in range(n_values)</p>
<p>array : n_values[i] is the number of categorical values in<br>X[:, i]. Each feature value should be in range(n_values[i])</p>
<p>Deprecated since version 0.20: The n_values keyword was deprecated in version 0.20 and will be removed in 0.22. Use categories instead.</p>
<p>categorical_features : ‘all’ or array of indices or mask, default=’all’<br>Specify what features are treated as categorical.</p>
<p>‘all’: All features are treated as categorical.<br>array of indices: Array of categorical feature indices.<br>mask: Array of length n_features and with dtype=bool.<br>Non-categorical features are always stacked to the right of the matrix.</p>
<p>Deprecated since version 0.20: The categorical_features keyword was deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.</p>
<h2 id="特征缩放-Feature-Scaling"><a href="#特征缩放-Feature-Scaling" class="headerlink" title="特征缩放 Feature Scaling"></a>特征缩放 Feature Scaling</h2><ul>
<li>因为两个特征向量之间的差异可以用欧氏距离来表示（勾股定理），如果任意一个特征向量过于巨大那么距离大差异就会更偏向特征值巨大的量，甚至完全取决于这个量，于是就需要缩放到一个数量级上</li>
<li>特征缩放 Feature Scaling后某些模型收敛会快很多，比如决策树算法（枝干过长）</li>
<li><p>特征缩放方法：<br><img src="/images/A-Z_ML/01.png" alt></p>
</li>
<li><p>是否需要对虚拟变量进行特征缩放。答：不一定，要根据模型结果。</p>
</li>
<li>是否需要对因变量y进行特征缩放？答：不一定，如果y为分类则不需要，如果y为连续则需要（线性回归）。</li>
</ul>
<pre><code># Feature Scaling
from sklearn.preprocessing import StandardScaler
sc_XStandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)
</code></pre>
      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/08/10/Data-Preprocessing-by-R/">Data Preprocessing by R</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/08/10/Data-Preprocessing-by-R/" class="archive-article-date"><time datetime="2019-08-10T11:08:09.000Z" itemprop="datePublished">August 10th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h2><script src="https://gist.github.com/SauronLee/d07b84f9caefd89dbc3f76a943bd8166.js"></script>

<ul>
<li>因子数据类型（有序因子&amp;无序因子），可以代替Python中的OneHotEncoder</li>
</ul>
<p>Usage<br>factor(x = character(), levels, labels = levels,<br>       exclude = NA, ordered = is.ordered(x), nmax = NA)</p>
<p>ordered(x, …)</p>
<p>is.factor(x)<br>is.ordered(x)</p>
<p>as.factor(x)<br>as.ordered(x)</p>
<p>addNA(x, ifany = FALSE)<br>Arguments<br>x<br>a vector of data, usually taking a small number of distinct values.</p>
<p>levels<br>an optional vector of the unique values (as character strings) that x might have taken. The default is the unique set of values taken by as.character(x), sorted into increasing order of x. Note that this set can be specified as smaller than sort(unique(x)).</p>
<p>labels<br>either an optional character vector of labels for the levels (in the same order as levels after removing those in exclude), or a character string of length 1. Duplicated values in labels can be used to map different values of x to the same factor level.</p>
<p>exclude<br>a vector of values to be excluded when forming the set of levels. This may be factor with the same level set as x or should be a character.</p>
<p>ordered<br>logical flag to determine if the levels should be regarded as ordered (in the order given).</p>
<p>nmax<br>an upper bound on the number of levels; see ‘Details’.</p>
<p>…<br>(in ordered(.)): any of the above, apart from ordered itself.</p>
<p>ifany<br>only add an NA level if it is used, i.e. if any(is.na(x)).</p>
<h2 id="Splitting-the-Dataset-into-the-Training-set-and-Test-set"><a href="#Splitting-the-Dataset-into-the-Training-set-and-Test-set" class="headerlink" title="Splitting the Dataset into the Training set and Test set"></a>Splitting the Dataset into the Training set and Test set</h2><pre><code># Data Preprocessing Template

# Importing the dataset
dataset = read.csv(&#39;Data.csv&#39;)
# dataset = dataset[, 2:3]

# Splitting the dataset into the Training set and Test set
# R语言安装packages
# install.packages(&#39;caTools&#39;)
# library(caTools) = 在packages里面打钩，推荐用library(caTools) 
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# split == TRUE为random出来的数据
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)

# Feature Scaling
# training_set[, 2:3] = scale(training_set[, 2:3])
# test_set[, 2:3] = scale(test_set[, 2:3])
</code></pre><ul>
<li>set.seed<br>Random Number Generation</li>
</ul>
<p>Usage<br>.Random.seed &lt;- c(rng.kind, n1, n2, \dots)</p>
<p>RNGkind(kind = NULL, normal.kind = NULL, sample.kind = NULL)<br>RNGversion(vstr)<br>set.seed(seed, kind = NULL, normal.kind = NULL, sample.kind = NULL)<br>Arguments<br>kind<br>character or NULL. If kind is a character string, set R’s RNG to the kind desired. Use “default” to return to the R default. See ‘Details’ for the interpretation of NULL.</p>
<p>normal.kind<br>character string or NULL. If it is a character string, set the method of Normal generation. Use “default” to return to the R default. NULL makes no change.</p>
<p>sample.kind<br>character string or NULL. If it is a character string, set the method of discrete uniform generation (used in sample, for instance). Use “default” to return to the R default. NULL makes no change.</p>
<p>seed<br>a single value, interpreted as an integer, or NULL (see ‘Details’).</p>
<p>vstr<br>a character string containing a version number, e.g., “1.6.2”. The default RNG configuration of the current R version is used if vstr is greater than the current version.</p>
<p>rng.kind<br>integer code in 0:k for the above kind.</p>
<p>n1, n2, …<br>integers. See the details for how many are required (which depends on rng.kind).</p>
<ul>
<li>sample.split<br>Split Data into Test and Train Set</li>
</ul>
<p>Usage<br> sample.split( Y, SplitRatio = 2/3, group = NULL )<br>Arguments<br>Y<br>Vector of data labels. If there are only a few labels (as is expected) than relative ratio of data in both subsets will be the same.</p>
<p>SplitRatio<br>Splitting ratio:</p>
<p>if (0&lt;=SplitRatio&lt;1) then SplitRatio fraction of points from Y will be set toTRUE</p>
<p>if (SplitRatio==1) then one random point from Y will be set to TRUE</p>
<p>if (SplitRatio&gt;1) then SplitRatio number of points from Y will be set to TRUE</p>
<p>group<br>Optional vector/list used when multiple copies of each sample are present. In such a case group contains unique sample labels, marking all copies of the same sample with the same label, and the function tries to place all copies in either train or test subset. If provided than has to have the same length as Y.</p>
<h1 id="特征缩放-Feature-Scaling"><a href="#特征缩放-Feature-Scaling" class="headerlink" title="特征缩放 Feature Scaling"></a>特征缩放 Feature Scaling</h1><ul>
<li>因为两个特征向量之间的差异可以用欧氏距离来表示（勾股定理），如果任意一个特征向量过于巨大那么距离大差异就会更偏向特征值巨大的量，甚至完全取决于这个量，于是就需要缩放到一个数量级上</li>
<li>特征缩放 Feature Scaling后某些模型收敛会快很多，比如决策树算法（枝干过长）</li>
<li><p>特征缩放方法：<br><img src="/images/A-Z_ML/01.png" alt></p>
</li>
<li><p>是否需要对虚拟变量进行特征缩放？答：不一定，要根据模型结果。</p>
</li>
<li>是否需要对因变量y进行特征缩放？答：不一定，如果y为分类则不需要，如果y为连续则需要（线性回归）。</li>
<li>在R里factor属于单独的类型不属于数字它属于分类的一个数据类型</li>
</ul>
<pre><code># Feature Scaling
training_set[,2:3] = scale(training_set[,2:3])
test_set[,2:3] = scale(test_set[,2:3])
</code></pre>
      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/07/13/CART-of-R-by-A-Z/">Decision Tree Classifier of R  by A-Z</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/07/13/CART-of-R-by-A-Z/" class="archive-article-date"><time datetime="2019-07-13T07:34:29.000Z" itemprop="datePublished">July 13th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/A-Z_ML/88.png" alt></p>
<ul>
<li>因为决策树用的是切线切割没有用到欧式距离所以不需要进行特征缩放</li>
</ul>
<script src="https://gist.github.com/SauronLee/5550de72b8e9ab228abb30178fe5dbb6.js"></script>

<hr>
<pre><code>
&gt; View(dataset)
&gt; y_pred
  2   4   5   9  12  18  19  20  22  29  32  34  35  38  45  46  48  52  66  69  74  75  82  84 
  0   0   0   0   0   0   1   1   0   0   1   0   1   0   0   0   0   0   0   0   1   0   0   1 
 85  86  87  89 103 104 107 108 109 117 124 126 127 131 134 139 148 154 156 159 162 163 170 175 
  0   1   0   0   1   1   0   1   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0 
176 193 199 200 208 213 224 226 228 229 230 234 236 237 239 241 255 264 265 266 273 274 281 286 
  0   0   0   0   1   1   1   0   1   0   0   1   1   0   1   1   0   0   1   1   1   1   1   1 
292 299 302 305 307 310 316 324 326 332 339 341 343 347 353 363 364 367 368 369 372 373 380 383 
  1   0   0   0   1   0   0   1   0   1   0   1   0   1   1   0   0   1   1   0   1   0   1   1 
389 392 395 400 
  1   1   0   1 
Levels: 0 1

&gt; cm
   y_pred
     0  1
  0 53 11
  1  6 30
</code></pre><p><img src="/images/A-Z_ML/89.png" alt><br><img src="/images/A-Z_ML/90.png" alt><br><img src="/images/A-Z_ML/91.png" alt></p>

      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/07/13/CART-of-Python-by-A-Z/">Decision Tree Classifier of Python by A-Z</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/07/13/CART-of-Python-by-A-Z/" class="archive-article-date"><time datetime="2019-07-13T07:34:19.000Z" itemprop="datePublished">July 13th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/A-Z_ML/85.png" alt></p>
<script src="https://gist.github.com/SauronLee/ef680bf345a816817042c7acf0503a39.js"></script>

<ul>
<li>由于过度拟合所以预测的非常差</li>
</ul>
<p><img src="/images/A-Z_ML/84.png" alt><br><img src="/images/A-Z_ML/86.png" alt></p>

      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/07/13/Bayes-Theorem-by-A-Z/">Bayes Theorem by A-Z</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/07/13/Bayes-Theorem-by-A-Z/" class="archive-article-date"><time datetime="2019-07-13T05:41:36.000Z" itemprop="datePublished">July 13th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/A-Z_ML/64.png" alt></p>
<ul>
<li>P(A)是先验概率P(A|B)是后验概率</li>
<li>B在朴素贝叶斯的分类器当中叫做特征，所以P(B)和P(A|B)不完全叫概率而叫做似然<br><img src="/images/A-Z_ML/65.png" alt></li>
<li>Plane Attack<br><img src="/images/A-Z_ML/66.png" alt><br><img src="/images/A-Z_ML/67.png" alt><br><img src="/images/A-Z_ML/68.png" alt><br><img src="/images/A-Z_ML/69.png" alt><br><img src="/images/A-Z_ML/70.png" alt><br><img src="/images/A-Z_ML/71.png" alt><br><img src="/images/A-Z_ML/72.png" alt><br><img src="/images/A-Z_ML/73.png" alt><br><img src="/images/A-Z_ML/74.png" alt><br><img src="/images/A-Z_ML/75.png" alt></li>
<li>缺少似然会降低计算量用于估计<br><img src="/images/A-Z_ML/76.png" alt></li>
</ul>

      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/07/12/NLP-Sentence-analysis/">NLP Sentence analysis</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/07/12/NLP-Sentence-analysis/" class="archive-article-date"><time datetime="2019-07-12T07:13:33.000Z" itemprop="datePublished">July 12th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="句法分析任务"><a href="#句法分析任务" class="headerlink" title="句法分析任务"></a>句法分析任务</h1><p><img src="/images/NLP/sentence_analysis_01.png" alt></p>
<h1 id="全局句法分析"><a href="#全局句法分析" class="headerlink" title="全局句法分析"></a>全局句法分析</h1><p><img src="/images/NLP/sentence_analysis_02.png" alt></p>
<h1 id="全局句法分析-1"><a href="#全局句法分析-1" class="headerlink" title="全局句法分析"></a>全局句法分析</h1><p><img src="/images/NLP/sentence_analysis_03.png" alt></p>
<h1 id="依存结构"><a href="#依存结构" class="headerlink" title="依存结构"></a>依存结构</h1><p><img src="/images/NLP/sentence_analysis_04.png" alt></p>
<ul>
<li>依存结构概念：</li>
</ul>
<ul>
<li>依照句法通过分析语言单位成分之前的依存关系解释其句法结构，主张句子中核心动词是支配其他成分的中心成分，而他本身却不受其他任何成分的支配，所有受支配成分都以某种关系从属于支配者</li>
</ul>
<ul>
<li>五个条件</li>
</ul>
<ul>
<li>一个句子中只有一个成分是独立的</li>
<li>句子的其他成分都从属于某一成分</li>
<li>如果成分A从属于成分B.而成分C在句子中位于A和B之间，那么，成分C或者从属于A，或者从属于B，或者从属于A和B之间的某一成分</li>
<li>中心成分左右两边的其他成分互相不发生关系<br><img src="/images/NLP/sentence_analysis_05.png" alt><h1 id="使用spacy进行语法分析"><a href="#使用spacy进行语法分析" class="headerlink" title="使用spacy进行语法分析"></a>使用spacy进行语法分析</h1></li>
</ul>
<ul>
<li>下载英文数据以及对应的模型 <code>python -m spacy download en</code></li>
</ul>
<script src="https://gist.github.com/SauronLee/c656cd3081b1931087aa6713cd267828.js"></script>
      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/07/12/Dataset-Business-Problem-Description-by-A-Z/">Dataset + Business Problem Description by A-Z</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/07/12/Dataset-Business-Problem-Description-by-A-Z/" class="archive-article-date"><time datetime="2019-07-11T17:57:51.000Z" itemprop="datePublished">July 12th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/A-Z_ML/07.png" alt></p>
<p><img src="/images/A-Z_ML/08.png" alt></p>
<ul>
<li>简单=多元<br>简单回归~多元回归向量的内积形式<br><img src="/images/A-Z_ML/09.png" alt></li>
<li>条件<br>1.数据是否是线性的<br>2.数据要有同样的方差<br>3,数据要呈现多元正态分布<br>4,我们的误差在不同的维度之间都必须是独立的<br>5,没有一个自变量是其他自变量的线性关系（因为只要两个自变量有逻辑关系那么整个预测就会被这种逻辑关系干扰）<br><img src="/images/A-Z_ML/10.png" alt></li>
<li>Dummy Data的处理</li>
<li>重点，在这里的【0，1】可以是任意的两个数，因为y=b_0+b_1*x这两个数只代表固定的两个数而已，两个维度中的变量，只是进行了整体的缩放。<br><img src="/images/A-Z_ML/11.png" alt><br><img src="/images/A-Z_ML/12.png" alt></li>
<li>虚拟变量陷阱=同时使用两个虚拟变量（会出现*条件5中的多重共线性）</li>
<li>如果加上D_5拟合后会出现误差极度接近为零=过拟合，冯诺依曼说过：“给我4个参数我可以拟合出一头大象，再给我一个参数我可以让这头大象鼻子竖在地上跳舞”</li>
<li>遇到2个以上的分类形式的虚拟变量的时候我们始终n-1，使得我们的维度不会溢出<br><img src="/images/A-Z_ML/13.png" alt><br><img src="/images/A-Z_ML/14.png" alt></li>
<li>对自变量的筛选极为重要，1，喂进去的如果是垃圾那么出来的也是垃圾，2，不容易解释自变量各自的意义和对模型的贡献最大<br><img src="/images/A-Z_ML/15.png" alt></li>
<li>刷选方法：<br>1，每个自变量都有用一个也不能舍去<br><img src="/images/A-Z_ML/16.png" alt><br>2，看每个自变量的显著性（反向淘汰）</li>
<li>门槛SL=0.05，对所有的自变量都做拟合求出P值（y=kx+b），取最高P值高于SL则去除（SL越小显著性越高）<br><img src="/images/A-Z_ML/17.png" alt><br>3，（顺向选择）和（反向淘汰）一样<br><img src="/images/A-Z_ML/18.png" alt><br>4，（双向淘汰）<br><img src="/images/A-Z_ML/19.png" alt><br>5，（信息量比较）最大信息熵</li>
<li>赤池信息量准则（一种信息打分的方式）对所有可能的模型进行打分，不适用过多自变量<br><img src="/images/A-Z_ML/20.png" alt></li>
</ul>

      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/07/11/NLP-Word-analysis/">NLP Word analysis</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/07/11/NLP-Word-analysis/" class="archive-article-date"><time datetime="2019-07-11T11:14:30.000Z" itemprop="datePublished">July 11th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="词法分析任务："><a href="#词法分析任务：" class="headerlink" title="词法分析任务："></a>词法分析任务：</h1><ul>
<li>将句子转换成词序列并标记句子中的词的词性</li>
<li>英文：用词的形态来表示语法变化的关系</li>
</ul>
<ul>
<li>英文的词法分析（曲折语）<br><img src="/images/NLP/word_analysis_02.png" alt></li>
<li>英文词识别，词形还原</li>
<li><p>未登陆词的处理</p>
</li>
<li><p>英文词性标注<br><img src="/images/NLP/word_analysis_01.png" alt></p>
</li>
</ul>
<ul>
<li><p>孤立语（汉语）</p>
</li>
<li><p>主要特点：1，缺乏词形变化；2，词序严格；3，虚词十分重要；4复合词多，派生词少 —语言学纲要</p>
</li>
</ul>
<h1 id="英语词法分析任务："><a href="#英语词法分析任务：" class="headerlink" title="英语词法分析任务："></a>英语词法分析任务：</h1><ul>
<li>单词识别（Tokenization）</li>
<li>词形还原（Lemmatization)</li>
<li><p>词性标注 POS(Part-of-Speech)Tagging</p>
</li>
<li><p>英语特点：词之间一般有边界标记，词的形态变化丰富<br><img src="/images/NLP/word_analysis_03.png" alt><br><img src="/images/NLP/word_analysis_04.png" alt><br><img src="/images/NLP/word_analysis_05.png" alt><br><img src="/images/NLP/word_analysis_06.png" alt><br><img src="/images/NLP/word_analysis_07.png" alt></p>
</li>
</ul>
<h1 id="中文词法分析任务："><a href="#中文词法分析任务：" class="headerlink" title="中文词法分析任务："></a>中文词法分析任务：</h1><ul>
<li>原始句子：警察正在详细调查事故原因</li>
<li>分词结果：警察/正在/详细/调查/事故/原因 （自动分词阶段）</li>
<li>词性标注结果：警察/NN 正在/AD 详细/AD 调查/VV 事故/NN 原因/NN</li>
</ul>
<p><img src="/images/NLP/word_analysis_08.png" alt><br><img src="/images/NLP/word_analysis_09.png" alt><br><img src="/images/NLP/word_analysis_10.png" alt><br><img src="/images/NLP/word_analysis_11.png" alt><br><img src="/images/NLP/word_analysis_12.png" alt></p>
<ul>
<li>分词方法：1，事先人工建立好分词规律比如量词前应该有数词（大量人工）2.自动分词算法（正向最大匹配+逆向最大匹配=双向最大匹配）3利用同现频率作为分词依据</li>
</ul>
<h1 id="英文使用NLTK"><a href="#英文使用NLTK" class="headerlink" title="英文使用NLTK"></a>英文使用NLTK</h1><script src="https://gist.github.com/SauronLee/315ce54c6032c09693284b9a04419b84.js"></script>

<h2 id="下载nltk"><a href="#下载nltk" class="headerlink" title="下载nltk"></a>下载nltk</h2><pre><code>conda activate tfpy36
ipython
import nltk
nltk.download()
</code></pre><h1 id="中文使用jieba"><a href="#中文使用jieba" class="headerlink" title="中文使用jieba"></a>中文使用jieba</h1><ul>
<li><a href="https://gitbub.com/fxsiy/jieba" target="_blank" rel="noopener">https://gitbub.com/fxsiy/jieba</a></li>
</ul>
<p><img src="/images/NLP/word_analysis_13.png" alt="issue"></p>
<p><a href="https://gist.github.com/SauronLee/8ad99cd9c995dd5ef5d83b7dfc0c1d17" target="_blank" rel="noopener">https://gist.github.com/SauronLee/8ad99cd9c995dd5ef5d83b7dfc0c1d17</a></p>
<h1 id="TFIDF"><a href="#TFIDF" class="headerlink" title="TFIDF"></a>TFIDF</h1><p><img src="/images/NLP/word_analysis_14.png" alt="issue"></p>
<h1 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h1><p><img src="/images/NLP/word_analysis_15.png" alt="issue"></p>
<h1 id="TextRank"><a href="#TextRank" class="headerlink" title="TextRank"></a>TextRank</h1><ul>
<li>将文本进行分词，去除停用词或词性刷选等操作之后，设定窗口为K，进行滑动，在窗口中共同出现的词之间即可建立起为无向边。<br><img src="/images/NLP/word_analysis_16.png" alt="issue"></li>
<li>TextRank提取关键词步骤</li>
<li>把给定的文本T按照完整的句子进行分割；</li>
<li>对于每个句子，进行分词和词性的标注处理，过滤掉停用词，只保留指定词性的单词，如名词，动词，形容词等，这些词形形成候选词</li>
<li>构建候选词关键词的词图G =（V，E)，其中V为节点集，由（2）生成候选词组，然后采用共现关系（cooccurrence）构造两点之间的边，两个节点之间存在的边仅当它们对应的词汇在长度为KDE窗口中共现；</li>
<li>根据PageRank原理中的衡量重要性公式，初始化各个节点的权重，然后迭代计算各个节点的权重，直到收敛；</li>
<li>对节点的权重进行倒序排列，从而得到最重要的个单词，作为关键词；</li>
<li>由（5）得到的最重要的T个单词，在原始文中进行标记，若形成相邻词组，则组合成多词关键词</li>
</ul>
<h1 id="使用Pkuseg进行中文分词-专业类别细分"><a href="#使用Pkuseg进行中文分词-专业类别细分" class="headerlink" title="使用Pkuseg进行中文分词(专业类别细分)"></a>使用Pkuseg进行中文分词(专业类别细分)</h1><p><img src="/images/NLP/word_analysis_17.png" alt="issue"></p>

      
    </div>
  </header>
</article>


  
    
    
    <article class="archive-article archive-type-post">
  <header class="archive-article-header">
    
  
    <h1 itemprop="name">
      <a class="archive-article-title" href="/2019/07/11/NLP-Corpus/">NLP_Corpus</a>
    </h1>
  


    <div class="article-datetime">
  <a href="/2019/07/11/NLP-Corpus/" class="archive-article-date"><time datetime="2019-07-11T10:42:21.000Z" itemprop="datePublished">July 11th</time></a>
</div>

    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/NLP/corpus_01.png" alt></p>
<h1 id="北京大学计算语言所语料库标记"><a href="#北京大学计算语言所语料库标记" class="headerlink" title="北京大学计算语言所语料库标记"></a>北京大学计算语言所语料库标记</h1><ul>
<li><a href="http://opendata.pku.edu.cn/dataverse/icl" target="_blank" rel="noopener">http://opendata.pku.edu.cn/dataverse/icl</a></li>
</ul>
<p><img src="/images/NLP/corpus_02.png" alt></p>
<h1 id="London-Lund英语口语语料库："><a href="#London-Lund英语口语语料库：" class="headerlink" title="London-Lund英语口语语料库："></a>London-Lund英语口语语料库：</h1><ul>
<li><a href="http://www.helsinki.fi/varieng/CoRD/corpora/LLC/" target="_blank" rel="noopener">http://www.helsinki.fi/varieng/CoRD/corpora/LLC/</a></li>
</ul>
<p><img src="/images/NLP/corpus_03.png" alt></p>
<h1 id="Tencent中文语料库-19年刚刚开源的"><a href="#Tencent中文语料库-19年刚刚开源的" class="headerlink" title="Tencent中文语料库-19年刚刚开源的"></a>Tencent中文语料库-19年刚刚开源的</h1><ul>
<li><a href="https://ai.tencent.com/ailab/nlp/data/Tencent_AILab_ChineseEmbedding.tar.gz" target="_blank" rel="noopener">https://ai.tencent.com/ailab/nlp/data/Tencent_AILab_ChineseEmbedding.tar.gz</a><br><img src="/images/NLP/corpus_04.png" alt></li>
</ul>
<h1 id="语料库的类型"><a href="#语料库的类型" class="headerlink" title="语料库的类型"></a>语料库的类型</h1><ul>
<li>异质性（heterogeneous）：简单无选材</li>
<li>同质性（homogeneous）：如TIPSTER只收集军事方面语料</li>
<li>系统性（systematic）：定好收据预料的规则，平衡性和系统性</li>
<li>专用性（specialized）：如北美人文科学语料库</li>
<li>单语语料库</li>
<li>双语多多语对齐语料库：平行语料库：篇章对齐；句子对齐、结构对齐<br><img src="/images/NLP/corpus_05.png" alt></li>
<li>生语语料库：未经加工</li>
<li>熟语语料库：带有切分，标注（词性标注，句法结构信息标注（树库）语义信息标注</li>
<li>共时语料库：一个时间段，横截面</li>
<li>历时语料库：与共时相对，纵剖面<br><img src="/images/NLP/corpus_06.png" alt><!-- ![issue](/images/NLP/corpus_07.png) -->
</li>
</ul>

      
    </div>
  </header>
</article>


  
  
    </div></section>
  


  <div id="page-nav">
    <nav><ul class="pagination"><li><a class="page-prev" rel="prev" href="/tags/Machine-Learning/page/3/"><i class="fa fa-chevron-left"></i> Prev</a></li><li><a class="page-number" href="/tags/Machine-Learning/">1</a></li><li><a class="page-number" href="/tags/Machine-Learning/page/2/">2</a></li><li><a class="page-number" href="/tags/Machine-Learning/page/3/">3</a></li><li class="active"><span class="page-number">4</span></li><li><a class="page-number" href="/tags/Machine-Learning/page/5/">5</a></li><li><a class="page-number" href="/tags/Machine-Learning/page/6/">6</a></li><li><a class="page-next" rel="next" href="/tags/Machine-Learning/page/5/">Next <i class="fa fa-chevron-right"></i></a></li></ul></nav>
  </div>


        </div>
        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
          
  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <p> Domain Tags Machine Learning, Deep Learning,  Front End Development, iOS Development, Statistics， <em>Python</em>, <em>R</em>, <em>Flutter</em>, <em>Swift</em>, <em>JavaScript</em>.</p>

</div>


  
  <div class="sidebar-module">
    <h4>Categories</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/math/">math</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/news/">news</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/project/">project</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/projects/">projects</a><span class="sidebar-module-list-count">5</span></li></ul>
  </div>




  
  <div class="sidebar-module">
    <h4>Tags</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/ANN/">ANN</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Calculus/">Calculus</a><span class="sidebar-module-list-count">6</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Computer-Vision/">Computer Vision</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Data-cleaning/">Data cleaning</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Deep-Learning/">Deep Learning</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/JavaScript/">JavaScript</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Linear-Algebra/">Linear Algebra</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Machine-Learning/">Machine Learning</a><span class="sidebar-module-list-count">51</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/NLP/">NLP</a><span class="sidebar-module-list-count">5</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Python/">Python</a><span class="sidebar-module-list-count">22</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/R/">R</a><span class="sidebar-module-list-count">15</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Reinforcement-Learning/">Reinforcement Learning</a><span class="sidebar-module-list-count">6</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Statistics/">Statistics</a><span class="sidebar-module-list-count">52</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/english/">english</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/git/">git</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/leetcode/">leetcode</a><span class="sidebar-module-list-count">5</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/linear-algebra/">linear algebra</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/nlp/">nlp</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/python/">python</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tag Cloud</h4>
    <p class="tagcloud">
      <a href="/tags/ANN/" style="font-size: 10px;">ANN</a> <a href="/tags/Calculus/" style="font-size: 15.56px;">Calculus</a> <a href="/tags/Computer-Vision/" style="font-size: 10px;">Computer Vision</a> <a href="/tags/Data-cleaning/" style="font-size: 13.33px;">Data cleaning</a> <a href="/tags/Deep-Learning/" style="font-size: 11.11px;">Deep Learning</a> <a href="/tags/JavaScript/" style="font-size: 13.33px;">JavaScript</a> <a href="/tags/Linear-Algebra/" style="font-size: 10px;">Linear Algebra</a> <a href="/tags/Machine-Learning/" style="font-size: 18.89px;">Machine Learning</a> <a href="/tags/NLP/" style="font-size: 14.44px;">NLP</a> <a href="/tags/Python/" style="font-size: 17.78px;">Python</a> <a href="/tags/R/" style="font-size: 16.67px;">R</a> <a href="/tags/Reinforcement-Learning/" style="font-size: 15.56px;">Reinforcement Learning</a> <a href="/tags/Statistics/" style="font-size: 20px;">Statistics</a> <a href="/tags/english/" style="font-size: 10px;">english</a> <a href="/tags/git/" style="font-size: 11.11px;">git</a> <a href="/tags/leetcode/" style="font-size: 14.44px;">leetcode</a> <a href="/tags/linear-algebra/" style="font-size: 12.22px;">linear algebra</a> <a href="/tags/nlp/" style="font-size: 10px;">nlp</a> <a href="/tags/python/" style="font-size: 10px;">python</a>
    </p>
  </div>


  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2020/10/">October 2020</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/10/">October 2019</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/09/">September 2019</a><span class="sidebar-module-list-count">30</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/08/">August 2019</a><span class="sidebar-module-list-count">20</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/07/">July 2019</a><span class="sidebar-module-list-count">11</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/06/">June 2019</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/05/">May 2019</a><span class="sidebar-module-list-count">6</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/02/">February 2019</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/08/">August 2018</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/05/">May 2018</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/04/">April 2018</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/03/">March 2018</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/02/">February 2018</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/12/">December 2017</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/10/">October 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/08/">August 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/06/">June 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/05/">May 2017</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/05/">May 2016</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="/2020/10/26/NLP-base-of-Greedy-notes/">NLP base of Greedy notes</a>
        </li>
      
        <li>
          <a href="/2020/10/20/Bayesian-Statistics-Notes-01/">Prof.Yeh Benson Statistics Notes</a>
        </li>
      
        <li>
          <a href="/2020/10/16/Sunannan-10-000-words/">Sunannan 10,000 words</a>
        </li>
      
        <li>
          <a href="/2019/10/05/EM-Arithmetic-by-Zou/">EM Arithmetic by Zou</a>
        </li>
      
        <li>
          <a href="/2019/09/30/Deep-Learning-Certificate-by-Coursera/">Deep Learning Certificate by Coursera</a>
        </li>
      
    </ul>
  </div>



        </div>
    </div>
  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2020 Sauron Lee<br>
       <!-- <a href="https://i.imgur.com/S8qHH1C.jpg" target="_blank"><b>@Sauron Lee</b></a>
       - -->
       <a href="https://github.com/SauronLee" target="_blank"> <b>GitHub</b></a>
       -
       <a href="https://leetcode.com/sauronlee/" target="_blank"> <b>Leetcode</b></a>
    </div>
  </div>
</footer>

  

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>

  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
